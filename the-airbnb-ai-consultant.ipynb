{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":110281,"databundleVersionId":13391012,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"border: 1px solid #444; padding: 20px; border-radius: 5px;\">\n\n<h1 style=\"margin-top: 0;\">Overview: The Airbnb AI Consultant</h1>\n\n<h3 style=\"color: #8a8787;\">The Problem</h3>\n<p style=\"font-size: 16px; line-height: 1.6;\">\nMillions of Airbnb hosts struggle with a key question: \"What makes a listing successful?\" They often rely on guesswork to write descriptions and choose photos, with no data-driven way to optimize their listing for a 5-star review.\n</p>\n\n<h3 style=\"color: #8a8787;\">Our Solution</h3>\n<p style=\"font-size: 16px; line-height: 1.6;\">\nThis project introduces <b>\"The Airbnb AI Consultant,\"</b> a complete, multimodal AI system built on Google Cloud's powerful tools. Our system analyzes a listing's text, photos, and core data to not only predict its success but to provide actionable, AI-generated advice for improvement.\n</p>\n\n<h3 style=\"color: #8a8787;\">The Technical Journey</h3>\n<ol style=\"font-size: 16px; line-height: 1.6;\">\n    <li><b>Exploratory Data Analysis (EDA):</b> We start with a raw dataset of ~45,000 Los Angeles listings to uncover key insights.</li>\n    <li><b>Multimodal Feature Engineering:</b> We use the <b>Google Vision API</b> to analyze listing photos and advanced NLP techniques to process text descriptions, creating over 800 predictive features.</li>\n    <li><b>Predictive Modeling:</b> We iteratively train and evaluate a classification model to predict whether a listing will achieve \"Top Tier\" status.</li>\n    <li><b>Generative AI:</b> We use our model's key findings as a data-driven input for a <b>Generative AI (Google's Gemini model)</b> to create the final \"AI Scorecard\" with personalized, expert suggestions for hosts.</li>\n</ol>\n<hr style=\"border: 1px solid #333;\">\n<h3 style=\"color: #8a8787;\">Project Assets</h3>\n<p style=\"font-size: 16px; text-align: center;\">\n    <a href=\"https://github.com/WafaaAlayoubi/The-Airbnb-AI-Consultant\" target=\"_blank\" style=\"text-decoration: none; color: #5B99E5; margin: 0 15px;\">\n        <b>GitHub Repository</b>\n    </a> |\n    <a href=\"https://www.linkedin.com/posts/wafaa-alayoubi_bigqueryaihackathon-keepbuilding-airbnb-activity-7372965271764013056-So1y?utm_source=share&utm_medium=member_desktop&rcm=ACoAACzaHu0BrGyAXxu34AXUPIqKi5z4hJlnvPQ\" target=\"_blank\" style=\"text-decoration: none; color: #5B99E5; margin: 0 15px;\">\n        <b>LinkedIn Post</b>\n    </a> |\n    <a href=\"https://medium.com/@wafaaelayoubi.w/i-built-an-ai-consultant-for-airbnb-hosts-with-google-cloud-5592ffb53b76\" target=\"_blank\" style=\"text-decoration: none; color: #5B99E5; margin: 0 15px;\">\n        <b>Medium Blog</b>\n    </a> |\n    <a href=\"https://youtu.be/GuUszMD0Mqo\" target=\"_blank\" style=\"text-decoration: none; color: #5B99E5; margin: 0 15px;\">\n        <b>YouTube Demo</b>\n    </a>\n</p>\n\n</div>","metadata":{}},{"cell_type":"markdown","source":"<h2 style=\"margin-top: 0; border-bottom: 2px solid #555; padding-bottom: 10px;\">Table of Contents</h2>\n<div style=\"border: 1px solid #444; padding: 15px; border-radius: 5px;\">\n    <ul style=\"list-style-type: none; padding-left: 0;\">\n        <li style=\"margin-bottom: 10px; font-size: 16px;\">\n            <a href=\"#Phase-1:-Exploratory-Data-Analysis-(EDA)\" style=\"text-decoration: none; color: #5B99E5;\">\n                <b>Phase 1:</b> Exploratory Data Analysis (EDA) & Cleaning\n            </a>\n        </li>\n        <li style=\"margin-bottom: 10px; font-size: 16px;\">\n            <a href=\"#Phase-2:-Computer-Vision-Analysis-with-Google-Vision-API\" style=\"text-decoration: none; color: #5B99E5;\">\n                <b>Phase 2:</b> Computer Vision Analysis\n            </a>\n        </li>\n        <li style=\"margin-bottom: 10px; font-size: 16px;\">\n            <a href=\"#Phase-3:-Predictive-Modeling-(The-BRAIN)\" style=\"text-decoration: none; color: #5B99E5;\">\n                <b>Phase 3:</b> Predictive Modeling\n            </a>\n        </li>\n        <li style=\"margin-bottom: 10px; font-size: 16px;\">\n            <a href=\"#Phase-4:-Insight-Generation-&-The-AI-Scorecard\" style=\"text-decoration: none; color: #5B99E5;\">\n                <b>Phase 4:</b> Insight Generation & The AI Scorecard\n            </a>\n        </li>\n        <li style=\"margin-bottom: 10px; font-size: 16px;\">\n            <a href=\"#Phase-5:-Conclusion-&-Future-Work\" style=\"text-decoration: none; color: #5B99E5;\">\n                <b>Phase 5:</b> Conclusion & Future Work\n            </a>\n        </li>\n        <li style=\"margin-bottom: 10px; font-size: 16px;\">\n            <a href=\"#Bonus:-Feedback-on-Google-Cloud-&-Kaggle\" style=\"text-decoration: none; color: #5B99E5;\">\n                <b>Bonus:</b> Feedback on Google Cloud & Kaggle\n            </a>\n        </li>\n        <li style=\"margin-top: 20px; font-size: 16px; border-top: 1px solid #444; padding-top: 10px;\">\n            <a href=\"#Appendix:-Other-Experiments.\" style=\"text-decoration: none; color: #999;\">\n                <i>Appendix: Other Model Experiments</i>\n            </a>\n        </li>\n    </ul>\n</div>","metadata":{}},{"cell_type":"markdown","source":"## Architecture Diagram\n![Untitled Diagram.drawio.png](attachment:cb68e17b-89dd-44e8-84c3-8338872650ca.png)","metadata":{},"attachments":{"cb68e17b-89dd-44e8-84c3-8338872650ca.png":{"image/png":"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"}}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nimport time\nimport warnings\n\nfrom google.cloud import bigquery\nfrom google.cloud import storage\nfrom google.cloud import vision\nfrom google.api_core.client_options import ClientOptions\n\nfrom kaggle_secrets import UserSecretsClient\n\nfrom tqdm.auto import tqdm\nimport ast \n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n\nfrom scipy.stats import uniform, randint\n\nimport xgboost as xgb\n\nfrom tqdm.notebook import tqdm\n\n# Import VADER\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nimport nltk\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:46:42.960615Z","iopub.execute_input":"2025-09-07T09:46:42.961295Z","iopub.status.idle":"2025-09-07T09:46:42.969744Z","shell.execute_reply.started":"2025-09-07T09:46:42.961267Z","shell.execute_reply":"2025-09-07T09:46:42.968634Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ignore harmless warnings to keep the notebook clean\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:46:42.971196Z","iopub.execute_input":"2025-09-07T09:46:42.971542Z","iopub.status.idle":"2025-09-07T09:46:42.996271Z","shell.execute_reply.started":"2025-09-07T09:46:42.971518Z","shell.execute_reply":"2025-09-07T09:46:42.995052Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"project_id = 'bq-hackathon-ab-123'\nclient = bigquery.Client(project=project_id)\nprint(f\"Successfully connected to BigQuery project: {project_id}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:46:42.998102Z","iopub.execute_input":"2025-09-07T09:46:42.998652Z","iopub.status.idle":"2025-09-07T09:46:43.020148Z","shell.execute_reply.started":"2025-09-07T09:46:42.998526Z","shell.execute_reply":"2025-09-07T09:46:43.019055Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the SQL query to select all data from our table\nsql = \"\"\"\n    SELECT *\n    FROM `bq-hackathon-ab-123.airbnb_analysis.raw_listings`\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:46:43.021212Z","iopub.execute_input":"2025-09-07T09:46:43.021461Z","iopub.status.idle":"2025-09-07T09:46:43.039887Z","shell.execute_reply.started":"2025-09-07T09:46:43.021438Z","shell.execute_reply":"2025-09-07T09:46:43.038392Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run the query and load the results into a Pandas DataFrame\nprint(\"Running query to load data...\")\ndf = client.query(sql).to_dataframe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:46:43.042354Z","iopub.execute_input":"2025-09-07T09:46:43.042667Z","iopub.status.idle":"2025-09-07T09:47:53.211183Z","shell.execute_reply.started":"2025-09-07T09:46:43.042641Z","shell.execute_reply":"2025-09-07T09:47:53.210284Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Verify the data loaded correctly\nprint(\"\\nData loaded successfully from BigQuery!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:53.213904Z","iopub.execute_input":"2025-09-07T09:47:53.214268Z","iopub.status.idle":"2025-09-07T09:47:53.220160Z","shell.execute_reply.started":"2025-09-07T09:47:53.214241Z","shell.execute_reply":"2025-09-07T09:47:53.219236Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Phase 1: Exploratory Data Analysis (EDA)\n\nOur first step is to perform a thorough Exploratory Data Analysis (EDA) to understand the structure, quality, and characteristics of our dataset.\n\n### Goal\nThe first step in any EDA is to perform a high-level \"health check\" on the dataset. We're not looking for deep insights yet. Instead, we want to understand the basic structure and identify any immediate, glaring issues. We will check:\n*   **Dimensions:** How big is the dataset (rows and columns)?\n*   **Data Types:** Are columns stored in the correct format (e.g., numbers as `int`/`float`, text as `object`)?\n*   **Missing Values:** Get a first glance at the scale of the null value problem.\n*   **Duplicates:** Check for any completely duplicated entries.","metadata":{}},{"cell_type":"code","source":"# --- Step 1: The First Contact ---\n\n# 1. Check the dimensions of the DataFrame (rows, columns)\nprint(f\"Dataset Shape: {df.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:53.221098Z","iopub.execute_input":"2025-09-07T09:47:53.221379Z","iopub.status.idle":"2025-09-07T09:47:53.245941Z","shell.execute_reply.started":"2025-09-07T09:47:53.221358Z","shell.execute_reply":"2025-09-07T09:47:53.244812Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Display the first 5 rows to get a feel for the data\nprint(\"\\n--- First 5 Rows ---\")\ndisplay(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:53.247154Z","iopub.execute_input":"2025-09-07T09:47:53.248372Z","iopub.status.idle":"2025-09-07T09:47:53.314242Z","shell.execute_reply.started":"2025-09-07T09:47:53.248333Z","shell.execute_reply":"2025-09-07T09:47:53.313238Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Display the last 5 rows to check for any summary rows or weird data at the end\nprint(\"\\n--- Last 5 Rows ---\")\ndisplay(df.tail())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:53.316984Z","iopub.execute_input":"2025-09-07T09:47:53.317376Z","iopub.status.idle":"2025-09-07T09:47:53.343286Z","shell.execute_reply.started":"2025-09-07T09:47:53.317353Z","shell.execute_reply":"2025-09-07T09:47:53.342190Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4. Get the concise summary of the DataFrame. This is the most critical part of this step!\n# It tells us column names, non-null counts, and data types (Dtype).\nprint(\"\\n--- DataFrame Info ---\")\n# Using verbose=True to ensure all columns are shown, even if there are many\ndf.info(verbose=True, show_counts=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:53.344361Z","iopub.execute_input":"2025-09-07T09:47:53.344806Z","iopub.status.idle":"2025-09-07T09:47:53.459052Z","shell.execute_reply.started":"2025-09-07T09:47:53.344783Z","shell.execute_reply":"2025-09-07T09:47:53.458131Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5. Check for any completely duplicate rows\nprint(f\"\\n--- Duplicate Rows ---\")\nprint(f\"Number of completely duplicate rows: {df.duplicated().sum()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:53.460125Z","iopub.execute_input":"2025-09-07T09:47:53.460401Z","iopub.status.idle":"2025-09-07T09:47:53.781391Z","shell.execute_reply.started":"2025-09-07T09:47:53.460378Z","shell.execute_reply":"2025-09-07T09:47:53.780237Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n--- Summary Statistics for Numerical Columns ---\")\ndf.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:53.783062Z","iopub.execute_input":"2025-09-07T09:47:53.783385Z","iopub.status.idle":"2025-09-07T09:47:53.977486Z","shell.execute_reply.started":"2025-09-07T09:47:53.783363Z","shell.execute_reply":"2025-09-07T09:47:53.976431Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.1 Initial Inspection\n\n*   **Dataset Shape:** The dataset is quite large and complex, with **45,421 rows** and **79 columns**. This indicates we have a rich set of features to explore, but we'll also need to be mindful of computational efficiency.\n\n*   **Target Variable:** The primary target variable for our prediction goal is `review_scores_rating`. We can see it's a `float64` type, which is appropriate. However, it has a significant number of missing values (only 32,849 non-null out of 45,421). This is a critical issue we'll need to address.\n\n*   **Key Issues Identified:**\n    *   **Massive Missing Values:** Several columns are almost unusable or require significant imputation.\n        *   `calendar_updated` is **100% null** and can be dropped immediately.\n        *   `license` is mostly null (only 12,882 non-null).\n        *   `neighborhood_overview`, `neighbourhood`, `host_about` are all less than 50% filled. This suggests they might be difficult to use reliably.\n        *   Many core features like `beds`, `bedrooms`, `bathrooms`, and `price` also have thousands of missing values.\n    *   **Data Type Mismatches:** These are critical cleaning tasks.\n        *   `price` is an `object` type, likely due to currency symbols (e.g., '$') and commas. It must be converted to a numeric type (`float`) to be used in modeling.\n        *   Date columns like `last_scraped`, `host_since`, `first_review`, and `last_review` are stored as `object`. They need to be converted to `datetime` objects to extract useful features like seasonality or host tenure.\n        *   Percentage columns like `host_response_rate` and `host_acceptance_rate` are `object`s, likely due to '%' signs. They need to be converted to numeric types.\n    *   **Duplicates:** There are **0 completely duplicate rows**, which is good news. However, we might still have duplicate *listings* based on `id` if the data was scraped multiple times, which we can investigate later.","metadata":{}},{"cell_type":"markdown","source":"## 1.2 Core Feature Selection\n\nTo make our analysis more manageable and focused, we select a subset of 13 \"golden\" columns that are most relevant to our project goal. This includes identifiers, descriptive text and images, key property features, price, and our target variable, the review score.\n\nBy examining the non-null counts for this subset, we can formulate a clear cleaning strategy:\n\n*   **Inputs:** Our core inputs, `description` and `picture_url`, are largely complete.\n*   **Target:** Our target variable, `review_scores_rating`, is missing for ~28% of listings.\n*   **Key Features:** `price` is missing for ~20% of listings, and other features like `beds` and `bedrooms` also have significant gaps.\n\n**Conclusion:** Any row missing the `review_scores_rating`, `price`, or `description` will be excluded from our final model training dataset, as these are essential for our analysis.","metadata":{}},{"cell_type":"code","source":"golden_columns = [\n    'id',\n    'name',\n    'description',\n    'picture_url',\n    'host_is_superhost',  \n    'room_type',\n    'property_type',\n    'accommodates',\n    'bathrooms_text',\n    'bedrooms',\n    'beds',\n    'amenities',\n    'price',\n    'review_scores_rating'\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:53.978294Z","iopub.execute_input":"2025-09-07T09:47:53.978561Z","iopub.status.idle":"2025-09-07T09:47:53.983845Z","shell.execute_reply.started":"2025-09-07T09:47:53.978540Z","shell.execute_reply":"2025-09-07T09:47:53.982682Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_selected = df[golden_columns].copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:53.984857Z","iopub.execute_input":"2025-09-07T09:47:53.985245Z","iopub.status.idle":"2025-09-07T09:47:54.018430Z","shell.execute_reply.started":"2025-09-07T09:47:53.985212Z","shell.execute_reply":"2025-09-07T09:47:54.017343Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Verify the new DataFrame\nprint(\"--- New DataFrame with Selected 'Golden' Columns ---\")\nprint(f\"The new shape is: {df_selected.shape}\")\nprint(\"\\nHere's a look at the first few rows:\")\ndisplay(df_selected.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:54.019958Z","iopub.execute_input":"2025-09-07T09:47:54.020432Z","iopub.status.idle":"2025-09-07T09:47:54.039378Z","shell.execute_reply.started":"2025-09-07T09:47:54.020385Z","shell.execute_reply":"2025-09-07T09:47:54.038337Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# n updated .info() to see the non-null counts for just these columns.\nprint(\"\\n--- Updated Info for Selected Columns ---\")\ndf_selected.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:54.040376Z","iopub.execute_input":"2025-09-07T09:47:54.040701Z","iopub.status.idle":"2025-09-07T09:47:54.092444Z","shell.execute_reply.started":"2025-09-07T09:47:54.040672Z","shell.execute_reply":"2025-09-07T09:47:54.091322Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.3 Data Cleaning & Quality Control\n\nWith our core features selected, we proceed with cleaning the data to create a high-quality dataset for modeling.","metadata":{}},{"cell_type":"code","source":"# Making a copy\ndf_cleaning = df_selected.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:54.093483Z","iopub.execute_input":"2025-09-07T09:47:54.093817Z","iopub.status.idle":"2025-09-07T09:47:54.112811Z","shell.execute_reply.started":"2025-09-07T09:47:54.093790Z","shell.execute_reply":"2025-09-07T09:47:54.111480Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 1.3.1 Handling Missing Values\nOur primary cleaning step is to remove any listings that are missing essential information. We filter the dataset, keeping only the rows that have a valid `review_scores_rating`, `description`, AND `price`. This aggressive but necessary step reduces our dataset to **26,589 high-quality, complete entries**, retaining approximately 59% of the original data.","metadata":{}},{"cell_type":"code","source":"# Handle Missing Values\n# We will drop any rows where our essential columns are empty.\n# These are 'review_scores_rating', 'description', and 'price'.\ninitial_rows = len(df_cleaning)\ndf_cleaning.dropna(subset=['review_scores_rating', 'description', 'price'], inplace=True)\nfinal_rows = len(df_cleaning)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:54.113958Z","iopub.execute_input":"2025-09-07T09:47:54.114339Z","iopub.status.idle":"2025-09-07T09:47:54.143336Z","shell.execute_reply.started":"2025-09-07T09:47:54.114295Z","shell.execute_reply":"2025-09-07T09:47:54.142040Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"--- 1. Handling Missing Values ---\")\nprint(f\"Initial number of rows: {initial_rows}\")\nprint(f\"Number of rows after dropping essential NaNs: {final_rows}\")\nprint(f\"Number of rows removed: {initial_rows - final_rows}\")\nprint(f\"Percentage of data retained: {100 * final_rows / initial_rows:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:54.144875Z","iopub.execute_input":"2025-09-07T09:47:54.145242Z","iopub.status.idle":"2025-09-07T09:47:54.152852Z","shell.execute_reply.started":"2025-09-07T09:47:54.145218Z","shell.execute_reply":"2025-09-07T09:47:54.151203Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 1.3.2 Checking for Duplicates\nA check for duplicate `id` values confirms that there are **no duplicate listings** in our dataset.","metadata":{}},{"cell_type":"code","source":"# Check for Duplicates\ninitial_rows = len(df_cleaning)\ndf_cleaning.drop_duplicates(subset=['id'], inplace=True)\nfinal_rows = len(df_cleaning)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:54.158288Z","iopub.execute_input":"2025-09-07T09:47:54.158626Z","iopub.status.idle":"2025-09-07T09:47:54.190843Z","shell.execute_reply.started":"2025-09-07T09:47:54.158600Z","shell.execute_reply":"2025-09-07T09:47:54.189776Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n--- Checking for Duplicates ---\")\nif initial_rows == final_rows:\n    print(\"No duplicate listing IDs found. Good!\")\nelse:\n    print(f\"Removed {initial_rows - final_rows} duplicate rows.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:54.192071Z","iopub.execute_input":"2025-09-07T09:47:54.192429Z","iopub.status.idle":"2025-09-07T09:47:54.201171Z","shell.execute_reply.started":"2025-09-07T09:47:54.192397Z","shell.execute_reply":"2025-09-07T09:47:54.199930Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 1.3.3 Correcting Data Types\nThe `price` column was converted from a text object (e.g., \"$110.00\") to a numerical `float` type, which is essential for any statistical analysis or modeling.\n\nThe result of this phase is a new DataFrame, `df_clean`, where our most critical columns are 100% complete and correctly formatted.","metadata":{}},{"cell_type":"code","source":"# Correct Data Types for 'price'\n# The 'price' column is an object (text) due to '$' and ','.\n# We need to remove these characters and convert it to a float.\nprint(\"\\n--- Correcting 'price' Data Type ---\")\nprint(f\"Original 'price' Dtype: {df_cleaning['price'].dtype}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:54.202359Z","iopub.execute_input":"2025-09-07T09:47:54.203351Z","iopub.status.idle":"2025-09-07T09:47:54.223154Z","shell.execute_reply.started":"2025-09-07T09:47:54.203324Z","shell.execute_reply":"2025-09-07T09:47:54.222242Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This line uses string operations to remove '$' and ',' then converts to a numeric type\ndf_cleaning['price'] = df_cleaning['price'].replace({'\\$': '', ',': ''}, regex=True).astype(float)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:54.224376Z","iopub.execute_input":"2025-09-07T09:47:54.225216Z","iopub.status.idle":"2025-09-07T09:47:54.247298Z","shell.execute_reply.started":"2025-09-07T09:47:54.225179Z","shell.execute_reply":"2025-09-07T09:47:54.246194Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"New 'price' Dtype: {df_cleaning['price'].dtype}\")\nprint(\"First 5 price values after cleaning:\")\nprint(df_cleaning['price'].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:54.248331Z","iopub.execute_input":"2025-09-07T09:47:54.248600Z","iopub.status.idle":"2025-09-07T09:47:54.270507Z","shell.execute_reply.started":"2025-09-07T09:47:54.248580Z","shell.execute_reply":"2025-09-07T09:47:54.268973Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Final Cleaned DataFrame ---\n# Let's assign this to a final, clean name for the rest of the project.\ndf_clean = df_cleaning.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:54.271343Z","iopub.execute_input":"2025-09-07T09:47:54.271749Z","iopub.status.idle":"2025-09-07T09:47:54.295166Z","shell.execute_reply.started":"2025-09-07T09:47:54.271724Z","shell.execute_reply":"2025-09-07T09:47:54.294190Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n--- Final Cleaned DataFrame Info ---\")\ndf_clean.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:54.296283Z","iopub.execute_input":"2025-09-07T09:47:54.296595Z","iopub.status.idle":"2025-09-07T09:47:54.339508Z","shell.execute_reply.started":"2025-09-07T09:47:54.296571Z","shell.execute_reply":"2025-09-07T09:47:54.338439Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.4 Visualizing Key Numerical Features\n\nTo understand the characteristics of our listings, we visualize the distributions of our most important numerical columns: `review_scores_rating` and `price`.","metadata":{}},{"cell_type":"code","source":"# Set the style for our plots for a professional look\nsns.set_style('whitegrid')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:54.340451Z","iopub.execute_input":"2025-09-07T09:47:54.340776Z","iopub.status.idle":"2025-09-07T09:47:54.345945Z","shell.execute_reply.started":"2025-09-07T09:47:54.340754Z","shell.execute_reply":"2025-09-07T09:47:54.345171Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 1.4.1 Review Scores Distribution\nThe distribution of review scores is heavily **left-skewed**, with a massive peak at the maximum rating of 5.0. This is typical for review data and indicates that most listings are highly rated. Our model's main challenge will be to identify the specific factors that differentiate a perfect 5.0 listing from a good (but not perfect) one.","metadata":{}},{"cell_type":"code","source":"# Distribution of Review Scores\nplt.figure(figsize=(12, 6))\nsns.histplot(df_clean['review_scores_rating'], bins=30, kde=True)\nplt.title('Distribution of Review Scores Rating', fontsize=16)\nplt.xlabel('Rating (1-5)', fontsize=12)\nplt.ylabel('Number of Listings', fontsize=12)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:54.346931Z","iopub.execute_input":"2025-09-07T09:47:54.347198Z","iopub.status.idle":"2025-09-07T09:47:55.065322Z","shell.execute_reply.started":"2025-09-07T09:47:54.347170Z","shell.execute_reply":"2025-09-07T09:47:55.064169Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 1.4.2 Price Distribution & Outliers\nThe distribution of price is heavily **right-skewed**, with the vast majority of listings priced under $500 per night. A small number of extremely expensive listings (outliers) stretch the distribution.\n\n**Actionable Insight:** These extreme price outliers can negatively impact model performance. We will later filter our dataset to focus on a more conventional price range (e.g., below the 99th percentile) to build a more robust and accurate model.","metadata":{}},{"cell_type":"code","source":"# Distribution of Price (Checking for Outliers)\nplt.figure(figsize=(12, 6))\nsns.histplot(df_clean['price'], bins=100, kde=False) # kde=False as the long tail is extreme\nplt.title('Distribution of Listing Prices', fontsize=16)\nplt.xlabel('Price (in USD)', fontsize=12)\nplt.ylabel('Number of Listings', fontsize=12)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:55.066556Z","iopub.execute_input":"2025-09-07T09:47:55.066987Z","iopub.status.idle":"2025-09-07T09:47:55.500923Z","shell.execute_reply.started":"2025-09-07T09:47:55.066944Z","shell.execute_reply":"2025-09-07T09:47:55.499814Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Let's also look at a boxplot for price to better see the outliers\nplt.figure(figsize=(12, 6))\nsns.boxplot(x=df_clean['price'])\nplt.title('Boxplot of Listing Prices to Identify Outliers', fontsize=16)\nplt.xlabel('Price (in USD)', fontsize=12)\nplt.xscale('log') # Use a log scale to better visualize the wide range of prices\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:55.502124Z","iopub.execute_input":"2025-09-07T09:47:55.502492Z","iopub.status.idle":"2025-09-07T09:47:56.077095Z","shell.execute_reply.started":"2025-09-07T09:47:55.502458Z","shell.execute_reply":"2025-09-07T09:47:56.075999Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.5 Analyzing Categorical Features: Room Type\n\nWe next explore the `room_type` of the listings to understand the dataset's composition and its relationship with review scores.","metadata":{}},{"cell_type":"markdown","source":"### 1.5.1 Composition\nThe count plot reveals that the dataset is dominated by **\"Entire home/apt\"** and **\"Private room\"** listings. \"Shared room\" and \"Hotel room\" are far less common. This means our model will have a much richer set of data to learn from for the two most common categories.","metadata":{}},{"cell_type":"code","source":"# Composition of Room Types\nplt.figure(figsize=(10, 6))\nsns.countplot(x='room_type', data=df_clean, order=df_clean['room_type'].value_counts().index)\nplt.title('Number of Listings by Room Type', fontsize=16)\nplt.xlabel('Room Type', fontsize=12)\nplt.ylabel('Number of Listings', fontsize=12)\nplt.xticks(rotation=45)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:56.078129Z","iopub.execute_input":"2025-09-07T09:47:56.078463Z","iopub.status.idle":"2025-09-07T09:47:56.328311Z","shell.execute_reply.started":"2025-09-07T09:47:56.078434Z","shell.execute_reply":"2025-09-07T09:47:56.327032Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 1.5.2 Ratings by Room Type\nA box plot of review scores for each room type reveals a key insight. While all room types have a very high median rating (close to 5.0), there are subtle but important differences in their distributions.\n\n**Key Insight:** The distribution for **\"Shared room\" listings is noticeably lower** than for \"Entire home/apt\" or \"Private room\". This suggests that while a typical shared room is well-rated, they have a higher tendency to receive scores in the 4.0-4.5 range, making it a more challenging category in which to achieve a perfect rating. This is a valuable feature for our future model.","metadata":{}},{"cell_type":"code","source":"# Review Scores by Room Type\nplt.figure(figsize=(12, 7))\nsns.boxplot(x='room_type', y='review_scores_rating', data=df_clean, order=df_clean['room_type'].value_counts().index)\nplt.title('Review Scores Distribution by Room Type', fontsize=16)\nplt.xlabel('Room Type', fontsize=12)\nplt.ylabel('Review Scores Rating', fontsize=12)\nplt.xticks(rotation=45)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:56.329498Z","iopub.execute_input":"2025-09-07T09:47:56.330044Z","iopub.status.idle":"2025-09-07T09:47:56.612042Z","shell.execute_reply.started":"2025-09-07T09:47:56.330017Z","shell.execute_reply":"2025-09-07T09:47:56.610910Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.6 Analyzing Numerical Relationships with a Correlation Matrix\n\nTo conclude our EDA, we create a correlation matrix to quantify the relationships between our key numerical features and the `review_scores_rating`.\n\nThe resulting heatmap reveals our most significant finding of the entire exploratory analysis:\n\n**Key Insight: Numerical features have almost no correlation with review scores.**\n\nAll of the numerical variables, including `price`, `accommodates`, `bedrooms`, and `beds`, show a correlation coefficient of close to zero (≤ 0.05) with the `review_scores_rating`. This is a powerful conclusion:\n\n*   **Price is not a predictor of quality:** More expensive listings do not receive higher ratings.\n*   **Size is not a predictor of quality:** Larger listings that accommodate more people or have more bedrooms do not receive higher ratings.\n\n**Conclusion of EDA:** This lack of correlation in the structured, numerical data strongly supports our project's core hypothesis. The factors that truly drive a 5-star guest experience are not captured by simple numbers. Instead, they are likely hidden within the unstructured data: the quality of the host's description, the amenities they offer, and the features visible in their listing photos. This provides a clear mandate for our multimodal approach, leveraging NLP and Computer Vision to unlock these deeper insights.","metadata":{}},{"cell_type":"code","source":"# Selecting only the most relevant numerical columns for the heatmap\nnumerical_cols_for_corr = [\n    'review_scores_rating',\n    'price',\n    'accommodates',\n    'bedrooms',\n    'beds'\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:56.613135Z","iopub.execute_input":"2025-09-07T09:47:56.613459Z","iopub.status.idle":"2025-09-07T09:47:56.618985Z","shell.execute_reply.started":"2025-09-07T09:47:56.613426Z","shell.execute_reply":"2025-09-07T09:47:56.617609Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate the correlation matrix\ncorrelation_matrix = df_clean[numerical_cols_for_corr].corr()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:56.620039Z","iopub.execute_input":"2025-09-07T09:47:56.620410Z","iopub.status.idle":"2025-09-07T09:47:56.643970Z","shell.execute_reply.started":"2025-09-07T09:47:56.620377Z","shell.execute_reply":"2025-09-07T09:47:56.642416Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create the heatmap\nplt.figure(figsize=(10, 8))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=.5)\nplt.title('Correlation Matrix of Key Numerical Features', fontsize=16)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:56.645166Z","iopub.execute_input":"2025-09-07T09:47:56.645678Z","iopub.status.idle":"2025-09-07T09:47:56.970394Z","shell.execute_reply.started":"2025-09-07T09:47:56.645579Z","shell.execute_reply":"2025-09-07T09:47:56.969196Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.7 Data Verification\n\nBefore proceeding to analysis, a crucial step is to verify the integrity of our data. We randomly sampled 5 listings and compared the `picture_url` from our dataset with the actual listing on the Airbnb website.\n\n**Findings:**\n*   The `picture_url` in our dataset consistently and accurately points to the **main \"hero\" image** for each listing. The data is reliable.\n*   As expected, our dataset only contains this single main image, not the full gallery of photos for each listing.\n\n**Strategic Implication:** This confirms our Computer Vision analysis will be focused on a powerful and relevant question: **\"What key feature is the host choosing to highlight in their single most important marketing photo, and how does that choice impact their review score?\"** This provides a clear and achievable scope for our CV task.","metadata":{}},{"cell_type":"code","source":"# --- Verify a few random image URLs ---\n\n# Get 5 random listings from our clean DataFrame\nrandom_samples = df_clean.sample(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:56.971337Z","iopub.execute_input":"2025-09-07T09:47:56.971617Z","iopub.status.idle":"2025-09-07T09:47:56.978356Z","shell.execute_reply.started":"2025-09-07T09:47:56.971596Z","shell.execute_reply":"2025-09-07T09:47:56.977319Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Loop through the random samples and print their info\nfor index, row in random_samples.iterrows():\n    print(\"-\" * 50)\n    print(f\"Listing Name: {row['name']}\")\n    print(f\"Listing ID: {row['id']}\")\n    print(f\"Image URL: {row['picture_url']}\")\n    print(f\"Airbnb Listing URL: https://www.airbnb.com/rooms/{row['id']}\")\n    print(\"-\" * 50)\n    print(\"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:56.979380Z","iopub.execute_input":"2025-09-07T09:47:56.979618Z","iopub.status.idle":"2025-09-07T09:47:57.006205Z","shell.execute_reply.started":"2025-09-07T09:47:56.979599Z","shell.execute_reply":"2025-09-07T09:47:57.005133Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.8 Saving the Cleaned Data to BigQuery\n\nTo finalize our data preparation phase, we will save our cleaned DataFrame (`df_clean`) back to Google BigQuery as a new table. This provides a clean, persistent starting point for all our future modeling and analysis work.","metadata":{}},{"cell_type":"code","source":"# Define the full table ID for our new table\n# Format is: project_id.dataset_id.table_name\ntable_id = f\"{project_id}.airbnb_analysis.cleaned_listings\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:57.007589Z","iopub.execute_input":"2025-09-07T09:47:57.007920Z","iopub.status.idle":"2025-09-07T09:47:57.031003Z","shell.execute_reply.started":"2025-09-07T09:47:57.007897Z","shell.execute_reply":"2025-09-07T09:47:57.030012Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Configure the job to write the DataFrame to BigQuery\n# write_disposition='WRITE_TRUNCATE' means if the table already exists, overwrite it.\njob_config = bigquery.LoadJobConfig(\n    write_disposition=\"WRITE_TRUNCATE\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:57.032136Z","iopub.execute_input":"2025-09-07T09:47:57.032410Z","iopub.status.idle":"2025-09-07T09:47:57.050486Z","shell.execute_reply.started":"2025-09-07T09:47:57.032381Z","shell.execute_reply":"2025-09-07T09:47:57.049192Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This sends our pandas DataFrame 'df_clean' to be saved as the table specified by 'table_id'.\njob = client.load_table_from_dataframe(\n    df_clean, table_id, job_config=job_config\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:57.051571Z","iopub.execute_input":"2025-09-07T09:47:57.051893Z","iopub.status.idle":"2025-09-07T09:47:59.284569Z","shell.execute_reply.started":"2025-09-07T09:47:57.051868Z","shell.execute_reply":"2025-09-07T09:47:59.283544Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Wait for the job to complete and print the result\njob.result()  # Waits for the job to finish\nprint(f\"Successfully saved {len(df_clean)} rows to the table: {table_id}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:47:59.285550Z","iopub.execute_input":"2025-09-07T09:47:59.285866Z","iopub.status.idle":"2025-09-07T09:48:02.007385Z","shell.execute_reply.started":"2025-09-07T09:47:59.285843Z","shell.execute_reply":"2025-09-07T09:48:02.005835Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Phase 2: Computer Vision Analysis with Google Vision API\n\nWith our data cleaned, we can now enrich it with insights from our unstructured data. In this phase, we will analyze the main listing image (`picture_url`) to extract key visual features. This is the \"Computer Vision\" component of our multimodal model.","metadata":{}},{"cell_type":"markdown","source":"## 2.1 API Setup and Connection Test\n\nFirst, we install the necessary library, set up our credentials securely using Kaggle Secrets, and run a test on a sample image to confirm our connection to the Google Vision API is working correctly.","metadata":{}},{"cell_type":"code","source":"# 1. Install the Google Cloud Vision library\n!pip install google-cloud-vision -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:02.008565Z","iopub.execute_input":"2025-09-07T09:48:02.008958Z","iopub.status.idle":"2025-09-07T09:48:07.835551Z","shell.execute_reply.started":"2025-09-07T09:48:02.008927Z","shell.execute_reply":"2025-09-07T09:48:07.834180Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get the API key we stored securely in Kaggle Secrets\nuser_secrets = UserSecretsClient()\napi_key = user_secrets.get_secret(\"GOOGLE_API_KEY\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:07.837079Z","iopub.execute_input":"2025-09-07T09:48:07.837488Z","iopub.status.idle":"2025-09-07T09:48:07.956558Z","shell.execute_reply.started":"2025-09-07T09:48:07.837441Z","shell.execute_reply":"2025-09-07T09:48:07.955551Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create the client using ONLY the client_options with our API key\n# This is the direct and correct way to use an API key.\nclient_options = ClientOptions(api_key=api_key)\nclient = vision.ImageAnnotatorClient(client_options=client_options)\n\nprint(\"Vision API client created successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:07.957770Z","iopub.execute_input":"2025-09-07T09:48:07.958195Z","iopub.status.idle":"2025-09-07T09:48:08.039355Z","shell.execute_reply.started":"2025-09-07T09:48:07.958165Z","shell.execute_reply":"2025-09-07T09:48:08.038452Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # (RUN ONCE)\n# # Test with a single, reliable image URL\n# image_url = \"https://a0.muscache.com/pictures/47759803/e70c0f85_original.jpg\"\n# image = vision.Image()\n# image.source.image_uri = image_url","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:08.040297Z","iopub.execute_input":"2025-09-07T09:48:08.040635Z","iopub.status.idle":"2025-09-07T09:48:08.045226Z","shell.execute_reply.started":"2025-09-07T09:48:08.040612Z","shell.execute_reply":"2025-09-07T09:48:08.043926Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # (RUN ONCE)\n# # Perform label detection on the image\n# print(f\"\\nAnalyzing test image: {image_url}\")\n# response = client.label_detection(image=image)\n# labels = response.label_annotations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:08.046389Z","iopub.execute_input":"2025-09-07T09:48:08.046668Z","iopub.status.idle":"2025-09-07T09:48:08.066850Z","shell.execute_reply.started":"2025-09-07T09:48:08.046647Z","shell.execute_reply":"2025-09-07T09:48:08.065968Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # (RUN ONCE)\n# # Print the results\n# print(\"\\n--- Labels Detected ---\")\n# for label in labels:\n#     print(f\"- {label.description} (Score: {label.score:.2f})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:08.068367Z","iopub.execute_input":"2025-09-07T09:48:08.068720Z","iopub.status.idle":"2025-09-07T09:48:08.093188Z","shell.execute_reply.started":"2025-09-07T09:48:08.068689Z","shell.execute_reply":"2025-09-07T09:48:08.091770Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.2 Creating the Image Analysis Function\n\nNow that our connection is established, we will create a robust Python function to analyze our image URLs. This function will call the Vision API, handle potential errors (like broken image links), and return a clean list of the top 5 most relevant labels for each image.","metadata":{}},{"cell_type":"code","source":"def get_image_labels(image_url):\n    \"\"\"\n    Analyzes an image from a URL using the Google Vision API.\n\n    Args:\n        image_url (str): The public URL of the image to analyze.\n\n    Returns:\n        list: A list of the top 5 label descriptions, or an empty list if an error occurs.\n    \"\"\"\n    # Add a small delay to avoid overwhelming the API\n    time.sleep(0.1)\n\n    try:\n        image = vision.Image()\n        image.source.image_uri = image_url\n        response = client.label_detection(image=image)\n        \n        # Check for errors in the API response itself\n        if response.error.message:\n            # print(f\"Error processing {image_url}: {response.error.message}\")\n            return []\n\n        # Extract just the description text from the top 5 labels\n        labels = [label.description for label in response.label_annotations[:5]]\n        return labels\n\n    except Exception as e:\n        # Catch any other exceptions (e.g., network errors, broken links)\n        # print(f\"An exception occurred for {image_url}: {e}\")\n        return []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:08.094363Z","iopub.execute_input":"2025-09-07T09:48:08.094721Z","iopub.status.idle":"2025-09-07T09:48:08.116019Z","shell.execute_reply.started":"2025-09-07T09:48:08.094687Z","shell.execute_reply":"2025-09-07T09:48:08.114943Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # (RUN ONCE)\n# # --- Test the function with a sample URL from our dataset ---\n# sample_url = df_clean['picture_url'].iloc[0] # Get the first image URL from our clean data\n# print(f\"Testing function with URL: {sample_url}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:08.117245Z","iopub.execute_input":"2025-09-07T09:48:08.118442Z","iopub.status.idle":"2025-09-07T09:48:08.139504Z","shell.execute_reply.started":"2025-09-07T09:48:08.118408Z","shell.execute_reply":"2025-09-07T09:48:08.138151Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # (RUN ONCE)\n# labels = get_image_labels(sample_url)\n# print(\"\\n--- Labels returned by our function ---\")\n# print(labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:08.140674Z","iopub.execute_input":"2025-09-07T09:48:08.141035Z","iopub.status.idle":"2025-09-07T09:48:08.164959Z","shell.execute_reply.started":"2025-09-07T09:48:08.141004Z","shell.execute_reply":"2025-09-07T09:48:08.163621Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.3 Applying the Function to a Data Sample\n\nAnalyzing all 26,000 images would take a long time and cost more than our $5 budget, To stay within our budget and time constraints, we will analyze a statistically significant sample of 1,000 listings. We will apply our `get_image_labels` function to each image URL in this sample and store the resulting list of labels in a new column called `image_labels`.\n\nTo ensure our project is both unbiased and scalable, we will create a permanent, stratified sample. We will add a new boolean column `is_in_1k_sample` to our main `df_clean` DataFrame. We use stratified sampling to select 1,000 listings and flag them as `True`. This entire DataFrame with the new flag is then saved back to BigQuery. This approach allows us to easily and reproducibly select our initial sample, and provides a clear path to scale our analysis in the future by sampling from the remaining, un-flagged data.","metadata":{}},{"cell_type":"code","source":"# # --- Create and Save a Permanent Stratified Sample Flag (RUN ONCE) ---\n\n# # Create the new column, default to False\n# df_clean['is_in_1k_sample'] = False\n\n# # Get the indices of our desired stratified sample\n# # We are just getting the IDs/indices of the rows, not the data itself yet.\n# _, sample_indices = train_test_split(\n#     df_clean.index,  # We stratify on the index\n#     test_size=1000,\n#     stratify=df_clean['room_type'],\n#     random_state=42\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:08.166259Z","iopub.execute_input":"2025-09-07T09:48:08.166617Z","iopub.status.idle":"2025-09-07T09:48:08.190804Z","shell.execute_reply.started":"2025-09-07T09:48:08.166594Z","shell.execute_reply":"2025-09-07T09:48:08.187068Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# (RUN ONCE)\n# # Set the flag to True for our chosen sample indices\n# df_clean.loc[sample_indices, 'is_in_1k_sample'] = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:08.191936Z","iopub.execute_input":"2025-09-07T09:48:08.192336Z","iopub.status.idle":"2025-09-07T09:48:08.222893Z","shell.execute_reply.started":"2025-09-07T09:48:08.192300Z","shell.execute_reply":"2025-09-07T09:48:08.221802Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# (RUN ONCE)\n# # Verify the flag was set correctly\n# print(\"--- Verification of the new flag ---\")\n# print(df_clean['is_in_1k_sample'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:08.235099Z","iopub.execute_input":"2025-09-07T09:48:08.235761Z","iopub.status.idle":"2025-09-07T09:48:08.248799Z","shell.execute_reply.started":"2025-09-07T09:48:08.235730Z","shell.execute_reply":"2025-09-07T09:48:08.247598Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# (RUN ONCE)\n# # --- Confirm the Stratified Sample is Balanced ---\n\n# # 1. Define our new sample and the full dataset\n# flagged_sample = df_clean[df_clean['is_in_1k_sample'] == True]\n# full_df = df_clean\n\n# print(\"--- Final Comparison: Flagged Sample vs. Full Dataset ---\")\n\n# # 2. Compare the proportions of 'room_type'\n# sample_counts = flagged_sample['room_type'].value_counts(normalize=True).rename('Sample')\n# full_counts = full_df['room_type'].value_counts(normalize=True).rename('Full Dataset')\n\n# # Combine into a single DataFrame for plotting and viewing\n# comparison_df = pd.concat([sample_counts, full_counts], axis=1) * 100\n\n# # 3. Plot the comparison\n# comparison_df.plot(kind='bar', figsize=(12, 7))\n# plt.title('Comparison of Room Type Proportions (%) - STRATIFIED SAMPLE', fontsize=16)\n# plt.ylabel('Percentage of Listings (%)')\n# plt.xticks(rotation=0)\n# plt.show()\n\n# # 4. Print the exact percentages to confirm\n# print(\"\\n--- Room Type Proportions ---\")\n# print(\"Note how the percentages in the 'Sample' column are now almost identical to the 'Full Dataset' column.\")\n# print(comparison_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:08.250145Z","iopub.execute_input":"2025-09-07T09:48:08.250562Z","iopub.status.idle":"2025-09-07T09:48:08.270722Z","shell.execute_reply.started":"2025-09-07T09:48:08.250527Z","shell.execute_reply":"2025-09-07T09:48:08.269369Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bq_client = bigquery.Client(project=project_id)\nprint(\"BigQuery client re-initialized.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:08.271851Z","iopub.execute_input":"2025-09-07T09:48:08.272233Z","iopub.status.idle":"2025-09-07T09:48:08.295536Z","shell.execute_reply.started":"2025-09-07T09:48:08.272200Z","shell.execute_reply":"2025-09-07T09:48:08.294349Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Save this new master DataFrame back to BigQuery, overwriting the old 'cleaned_listings' # (RUN ONCE)\n# table_id = f\"{project_id}.airbnb_analysis.cleaned_listings\"\n# job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n# job = bq_client.load_table_from_dataframe(\n#     df_clean, table_id, job_config=job_config\n# )\n# job.result()  # Wait for the job to finish","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:08.296405Z","iopub.execute_input":"2025-09-07T09:48:08.296769Z","iopub.status.idle":"2025-09-07T09:48:08.320471Z","shell.execute_reply.started":"2025-09-07T09:48:08.296738Z","shell.execute_reply":"2025-09-07T09:48:08.319184Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(f\"\\nSuccessfully saved 'df_clean' with the new 'is_in_1k_sample' flag back to {table_id}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:08.322074Z","iopub.execute_input":"2025-09-07T09:48:08.322482Z","iopub.status.idle":"2025-09-07T09:48:08.345912Z","shell.execute_reply.started":"2025-09-07T09:48:08.322449Z","shell.execute_reply":"2025-09-07T09:48:08.344879Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # --- Select the Flagged Sample and Analyze Images (RUN ONCE) ---\n\n# # Select ONLY the rows we just flagged\n# df_api_sample = df_clean[df_clean['is_in_1k_sample'] == True].copy()\n# print(f\"Selected our permanent sample of {len(df_api_sample)} images to analyze.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:08.346606Z","iopub.execute_input":"2025-09-07T09:48:08.346983Z","iopub.status.idle":"2025-09-07T09:48:08.367005Z","shell.execute_reply.started":"2025-09-07T09:48:08.346960Z","shell.execute_reply":"2025-09-07T09:48:08.365783Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # (RUN ONCE)\n# tqdm.pandas()\n# print(\"Analyzing images... (This will take a few minutes)\")\n# df_api_sample['image_labels'] = df_api_sample['picture_url'].progress_apply(get_image_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:08.368214Z","iopub.execute_input":"2025-09-07T09:48:08.368537Z","iopub.status.idle":"2025-09-07T09:48:08.391663Z","shell.execute_reply.started":"2025-09-07T09:48:08.368515Z","shell.execute_reply":"2025-09-07T09:48:08.390403Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # (RUN ONCE)\n# output_filename = 'airbnb_stratified_1k_sample_with_labels.csv'\n# df_api_sample.to_csv(output_filename, index=False)\n# print(f\"\\nImage analysis complete! Results saved to '{output_filename}'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:08.392788Z","iopub.execute_input":"2025-09-07T09:48:08.393156Z","iopub.status.idle":"2025-09-07T09:48:08.416244Z","shell.execute_reply.started":"2025-09-07T09:48:08.393097Z","shell.execute_reply":"2025-09-07T09:48:08.414956Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.4 Loading the Enriched Dataset\n\nWith our image analysis complete and the results securely saved to Google Cloud Storage, our final step in this phase is to load this new, enriched dataset. This `df_final_sample` DataFrame, containing our 1,000 listings and their corresponding image labels, will now serve as the foundation for our predictive modeling and generative AI phases.","metadata":{}},{"cell_type":"code","source":"# Ensure we are authenticated with Google Cloud\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nuser_credential = user_secrets.get_gcloud_credential()\nuser_secrets.set_tensorflow_credential(user_credential)\nprint(\"Authenticated with Google Cloud.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:08.417539Z","iopub.execute_input":"2025-09-07T09:48:08.418778Z","iopub.status.idle":"2025-09-07T09:48:08.553426Z","shell.execute_reply.started":"2025-09-07T09:48:08.418738Z","shell.execute_reply":"2025-09-07T09:48:08.552380Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the direct GCS path to our results file\ngcs_path = 'gs://bq-hackathon-wa-data/results/airbnb_stratified_1k_sample_with_labels.csv'\n\n# Use pandas to read the CSV directly from the GCS path\nprint(f\"Loading data from: {gcs_path}\")\ndf_final_sample = pd.read_csv(gcs_path, converters={'image_labels': ast.literal_eval})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:08.554433Z","iopub.execute_input":"2025-09-07T09:48:08.554763Z","iopub.status.idle":"2025-09-07T09:48:09.766003Z","shell.execute_reply.started":"2025-09-07T09:48:08.554731Z","shell.execute_reply":"2025-09-07T09:48:09.764926Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Verify the Results ---\nprint(\"\\nSuccessfully loaded enriched data!\")\nprint(f\"The final sample has {df_final_sample.shape[0]} rows and {df_final_sample.shape[1]} columns.\")\nprint(\"\\nHere's a look at our final, model-ready data:\")\ndisplay(df_final_sample[['name', 'review_scores_rating', 'image_labels']].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:09.767001Z","iopub.execute_input":"2025-09-07T09:48:09.767303Z","iopub.status.idle":"2025-09-07T09:48:09.782257Z","shell.execute_reply.started":"2025-09-07T09:48:09.767281Z","shell.execute_reply":"2025-09-07T09:48:09.781240Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Phase 3: Predictive Modeling (The BRAIN)\n\nWith our enriched dataset ready, we can now build the predictive core of our AI consultant. The goal of this phase is to train a machine learning model that can predict a listing's `review_scores_rating` based on its features.\n\nThis process begins with **Feature Engineering**, where we transform our raw text and image data into a numerical format that the model can understand.\n\n## 3.1 Feature Engineering for Image Labels\n\nOur first step is to convert our `image_labels` column into a format suitable for modeling. We will use a technique called **One-Hot Encoding**. This will create a new binary (1/0) column for each of the most common image labels found in our data, transforming our visual data into powerful numerical features.","metadata":{}},{"cell_type":"code","source":"# --- Part 3.1: Feature Engineering - One-Hot Encode Image Labels ---\n\n# This will be our main modeling DataFrame\ndf_model = df_final_sample.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:09.783469Z","iopub.execute_input":"2025-09-07T09:48:09.783889Z","iopub.status.idle":"2025-09-07T09:48:09.807691Z","shell.execute_reply.started":"2025-09-07T09:48:09.783805Z","shell.execute_reply":"2025-09-07T09:48:09.806462Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Initialize the MultiLabelBinarizer\n# This is a special tool from scikit-learn for handling columns that contain lists of labels.\nmlb = MultiLabelBinarizer()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:09.808918Z","iopub.execute_input":"2025-09-07T09:48:09.809268Z","iopub.status.idle":"2025-09-07T09:48:09.827227Z","shell.execute_reply.started":"2025-09-07T09:48:09.809232Z","shell.execute_reply":"2025-09-07T09:48:09.826155Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Fit and transform the 'image_labels' column\n# This creates a new DataFrame where each column is a unique label and each value is 1 or 0.\nencoded_labels = mlb.fit_transform(df_model['image_labels'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:09.828265Z","iopub.execute_input":"2025-09-07T09:48:09.828585Z","iopub.status.idle":"2025-09-07T09:48:09.855143Z","shell.execute_reply.started":"2025-09-07T09:48:09.828553Z","shell.execute_reply":"2025-09-07T09:48:09.853952Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Create a new DataFrame from the encoded labels\n# We'll give the new columns clear names, like 'has_label_Bed'.\nlabel_df = pd.DataFrame(encoded_labels, columns=[f\"has_label_{cls.replace(' ', '_').lower()}\" for cls in mlb.classes_])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:09.856164Z","iopub.execute_input":"2025-09-07T09:48:09.856412Z","iopub.status.idle":"2025-09-07T09:48:09.874997Z","shell.execute_reply.started":"2025-09-07T09:48:09.856394Z","shell.execute_reply":"2025-09-07T09:48:09.873790Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4. Concatenate the new label DataFrame with our main DataFrame\n# We need to make sure the indices align for a correct merge.\ndf_model.reset_index(drop=True, inplace=True)\nlabel_df.reset_index(drop=True, inplace=True)\ndf_model = pd.concat([df_model, label_df], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:09.876369Z","iopub.execute_input":"2025-09-07T09:48:09.876782Z","iopub.status.idle":"2025-09-07T09:48:09.902375Z","shell.execute_reply.started":"2025-09-07T09:48:09.876748Z","shell.execute_reply":"2025-09-07T09:48:09.901372Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Verify the Results ---\nprint(\"Successfully created one-hot encoded features from image labels.\")\nprint(f\"The DataFrame now has {df_model.shape[1]} columns.\")\nprint(\"\\nHere's a sample of the new 'has_label_' columns:\")\n\n# To make the output readable, find a few interesting columns to display\n# Let's find columns for common labels like 'bed', 'swimming_pool', and 'kitchen'\ndisplay_cols = ['image_labels']\nif 'has_label_bed' in df_model.columns: display_cols.append('has_label_bed')\nif 'has_label_swimming_pool' in df_model.columns: display_cols.append('has_label_swimming_pool')\nif 'has_label_kitchen' in df_model.columns: display_cols.append('has_label_kitchen')\n\ndisplay(df_model[display_cols].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:09.903462Z","iopub.execute_input":"2025-09-07T09:48:09.903896Z","iopub.status.idle":"2025-09-07T09:48:09.930302Z","shell.execute_reply.started":"2025-09-07T09:48:09.903855Z","shell.execute_reply":"2025-09-07T09:48:09.929396Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.2 Feature Engineering for Text Data (TF-IDF)\n\nNext, we process our primary text feature: the `description`. We will use the **TF-IDF (Term Frequency-Inverse Document Frequency)** vectorization technique. This will convert the raw text into a matrix of numerical features, where each feature represents the importance of a specific word to a listing's description. This allows our model to learn which keywords are most associated with high or low ratings.","metadata":{}},{"cell_type":"code","source":"# --- Part 3.2: Feature Engineering - TF-IDF for Descriptions ---\n\n# 1. Initialize the TfidfVectorizer\n# We'll set some parameters to get the best results:\n# - max_features=500: We'll only keep the top 500 most important words. This prevents having too many columns.\n# - stop_words='english': Automatically removes common English words like 'the', 'a', 'is'.\n# - min_df=5: Only consider words that appear in at least 5 different descriptions. This removes very rare, possibly misspelled words.\ntfidf = TfidfVectorizer(max_features=500, stop_words='english', min_df=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:09.931512Z","iopub.execute_input":"2025-09-07T09:48:09.931865Z","iopub.status.idle":"2025-09-07T09:48:09.956262Z","shell.execute_reply.started":"2025-09-07T09:48:09.931835Z","shell.execute_reply":"2025-09-07T09:48:09.955386Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Fit and transform the 'description' column\n# This creates a sparse matrix where each column is a word and each value is its TF-IDF score.\ntfidf_features = tfidf.fit_transform(df_model['description'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:09.957317Z","iopub.execute_input":"2025-09-07T09:48:09.957682Z","iopub.status.idle":"2025-09-07T09:48:10.054072Z","shell.execute_reply.started":"2025-09-07T09:48:09.957628Z","shell.execute_reply":"2025-09-07T09:48:10.053000Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Create a new DataFrame from the TF-IDF features\n# We'll give the new columns clear names, like 'keyword_beach'.\ntfidf_df = pd.DataFrame(tfidf_features.toarray(), columns=[f\"keyword_{word}\" for word in tfidf.get_feature_names_out()])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:10.055224Z","iopub.execute_input":"2025-09-07T09:48:10.055499Z","iopub.status.idle":"2025-09-07T09:48:10.064099Z","shell.execute_reply.started":"2025-09-07T09:48:10.055479Z","shell.execute_reply":"2025-09-07T09:48:10.063065Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4. Concatenate the new TF-IDF DataFrame with our main DataFrame\n# The indices should already be aligned, but resetting is a safe practice.\ndf_model.reset_index(drop=True, inplace=True)\ntfidf_df.reset_index(drop=True, inplace=True)\ndf_model = pd.concat([df_model, tfidf_df], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:10.065268Z","iopub.execute_input":"2025-09-07T09:48:10.065543Z","iopub.status.idle":"2025-09-07T09:48:10.089410Z","shell.execute_reply.started":"2025-09-07T09:48:10.065498Z","shell.execute_reply":"2025-09-07T09:48:10.088088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Verify the Results ---\nprint(\"Successfully created TF-IDF features from descriptions.\")\nprint(f\"The DataFrame now has {df_model.shape[1]} columns.\")\nprint(\"\\nHere's a sample of the new 'keyword_' columns:\")\n\n# Let's display a few potential keywords to see the result\ndisplay_cols = ['description']\nif 'keyword_beach' in df_model.columns: display_cols.append('keyword_beach')\nif 'keyword_cozy' in df_model.columns: display_cols.append('keyword_cozy')\nif 'keyword_luxury' in df_model.columns: display_cols.append('keyword_luxury')\n\ndisplay(df_model[display_cols].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:10.090275Z","iopub.execute_input":"2025-09-07T09:48:10.090657Z","iopub.status.idle":"2025-09-07T09:48:10.107600Z","shell.execute_reply.started":"2025-09-07T09:48:10.090621Z","shell.execute_reply":"2025-09-07T09:48:10.106312Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.3 Baseline Model Training and Evaluation\n\nWe will now train our first predictive model. This initial model will serve as our **baseline**. It is trained on the full, feature-engineered dataset without any outlier removal or advanced tuning. Our goal is to establish a starting performance metric (R²) that we will systematically try to improve upon in the following steps.\n\nWe will use a `Pipeline` to ensure a robust, leak-proof workflow. This pipeline will handle imputation of missing numerical values and one-hot encoding of categorical features before feeding the data to a powerful `XGBoost` regressor.","metadata":{}},{"cell_type":"code","source":"# --- Part 3.3: Train and Evaluate the Predictive Model ---\n\n# 1. Define our Features (X) and Target (y)\n# We select all columns we want the model to potentially learn from.\ny = df_model['review_scores_rating']\nX = df_model.drop(columns=[\n    'review_scores_rating', 'id', 'name', 'description',\n    'picture_url', 'amenities', 'image_labels'\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:10.108729Z","iopub.execute_input":"2025-09-07T09:48:10.109067Z","iopub.status.idle":"2025-09-07T09:48:10.137001Z","shell.execute_reply.started":"2025-09-07T09:48:10.109032Z","shell.execute_reply":"2025-09-07T09:48:10.135885Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Split the Data FIRST to prevent data leakage\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:10.138020Z","iopub.execute_input":"2025-09-07T09:48:10.138294Z","iopub.status.idle":"2025-09-07T09:48:10.166088Z","shell.execute_reply.started":"2025-09-07T09:48:10.138271Z","shell.execute_reply":"2025-09-07T09:48:10.164952Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Create the preprocessing pipeline\n# This pipeline will handle different column types separately and correctly.\n# It handles imputation and encoding INSIDE the pipeline, after the split.\n\n# Identify categorical and numerical columns\ncategorical_features = ['room_type', 'property_type', 'bathrooms_text']\nnumerical_features = X.select_dtypes(include=['int64', 'float64', 'bool']).columns\n\n# Create the preprocessor\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', SimpleImputer(strategy='median'), numerical_features),\n        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n    ],\n    remainder='passthrough' # Keep the other columns (our TF-IDF and image labels)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:10.167587Z","iopub.execute_input":"2025-09-07T09:48:10.167944Z","iopub.status.idle":"2025-09-07T09:48:10.191421Z","shell.execute_reply.started":"2025-09-07T09:48:10.167913Z","shell.execute_reply":"2025-09-07T09:48:10.190455Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4. Define the model\n# We'll use XGBoost, a powerful and popular gradient boosting model.\nmodel = xgb.XGBRegressor(random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:10.192750Z","iopub.execute_input":"2025-09-07T09:48:10.193082Z","iopub.status.idle":"2025-09-07T09:48:10.198307Z","shell.execute_reply.started":"2025-09-07T09:48:10.193052Z","shell.execute_reply":"2025-09-07T09:48:10.197257Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5. Create the full pipeline\n# This chains the preprocessing and the model together.\npipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                           ('regressor', model)])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:10.199462Z","iopub.execute_input":"2025-09-07T09:48:10.199799Z","iopub.status.idle":"2025-09-07T09:48:10.220194Z","shell.execute_reply.started":"2025-09-07T09:48:10.199774Z","shell.execute_reply":"2025-09-07T09:48:10.219178Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6. Train the pipeline on the TRAINING data\nprint(\"--- Training the model ---\")\npipeline.fit(X_train, y_train)\nprint(\"Model training complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:10.221408Z","iopub.execute_input":"2025-09-07T09:48:10.221800Z","iopub.status.idle":"2025-09-07T09:48:11.406469Z","shell.execute_reply.started":"2025-09-07T09:48:10.221774Z","shell.execute_reply":"2025-09-07T09:48:11.405735Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 7. Make predictions on the unseen TESTING data\nprint(\"\\n--- Evaluating the model ---\")\ny_pred = pipeline.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:11.407357Z","iopub.execute_input":"2025-09-07T09:48:11.407603Z","iopub.status.idle":"2025-09-07T09:48:11.442419Z","shell.execute_reply.started":"2025-09-07T09:48:11.407584Z","shell.execute_reply":"2025-09-07T09:48:11.441334Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 8. Evaluate the performance\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"Mean Squared Error (MSE): {mse:.4f}\")\nprint(f\"R-squared (R²): {r2:.4f}\")\n\n# Let's look at a few predictions vs. actuals\nprediction_comparison = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred}).head(10)\nprint(\"\\nSample of Predictions vs. Actuals:\")\nprint(prediction_comparison)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:11.443059Z","iopub.execute_input":"2025-09-07T09:48:11.444079Z","iopub.status.idle":"2025-09-07T09:48:11.456700Z","shell.execute_reply.started":"2025-09-07T09:48:11.444050Z","shell.execute_reply":"2025-09-07T09:48:11.456037Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.4 Model Improvement Iteration 1: Handling Price Outliers\n\nOur EDA revealed that the `price` column contains extreme outliers. These high-value listings can disproportionately influence the model and may not be representative of the general market.\n\n**Hypothesis:** By removing the most extreme price outliers, our model will be able to learn more effectively from the core majority of the data, leading to an improved R² score.\n\n**Action:** We will filter our dataset to remove the top 1% of the most expensive listings and re-train our model.","metadata":{}},{"cell_type":"code","source":"# --- Part 3.4: Iteration 1 - Remove Price Outliers ---\n\n# 1. Determine the 99th percentile price threshold\nprice_cap = df_model['price'].quantile(0.99)\nprint(f\"The 99th percentile price is: ${price_cap:.2f}. We will remove listings priced above this.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:11.457275Z","iopub.execute_input":"2025-09-07T09:48:11.457485Z","iopub.status.idle":"2025-09-07T09:48:11.478211Z","shell.execute_reply.started":"2025-09-07T09:48:11.457467Z","shell.execute_reply":"2025-09-07T09:48:11.477173Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Create the new, filtered DataFrame\ndf_no_outliers = df_model[df_model['price'] < price_cap].copy()\nprint(f\"Original number of listings: {len(df_model)}\")\nprint(f\"Number of listings after removing outliers: {len(df_no_outliers)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:11.479337Z","iopub.execute_input":"2025-09-07T09:48:11.479644Z","iopub.status.idle":"2025-09-07T09:48:11.505524Z","shell.execute_reply.started":"2025-09-07T09:48:11.479623Z","shell.execute_reply":"2025-09-07T09:48:11.504707Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Re-define X and y with the new outlier-removed data\ny_no_outliers = df_no_outliers['review_scores_rating']\nX_no_outliers = df_no_outliers.drop(columns=[\n    'review_scores_rating', 'id', 'name', 'description',\n    'picture_url', 'amenities', 'image_labels'\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:11.506551Z","iopub.execute_input":"2025-09-07T09:48:11.506985Z","iopub.status.idle":"2025-09-07T09:48:11.522034Z","shell.execute_reply.started":"2025-09-07T09:48:11.506892Z","shell.execute_reply":"2025-09-07T09:48:11.520931Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4. Split the new data\nX_train_no, X_test_no, y_train_no, y_test_no = train_test_split(\n    X_no_outliers, y_no_outliers, test_size=0.2, random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:11.523387Z","iopub.execute_input":"2025-09-07T09:48:11.523714Z","iopub.status.idle":"2025-09-07T09:48:11.545397Z","shell.execute_reply.started":"2025-09-07T09:48:11.523683Z","shell.execute_reply":"2025-09-07T09:48:11.544523Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5. Train the same pipeline on the new, cleaner data\nprint(\"\\n--- Training model on data with outliers removed ---\")\npipeline.fit(X_train_no, y_train_no)\nprint(\"Model training complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:11.546403Z","iopub.execute_input":"2025-09-07T09:48:11.546680Z","iopub.status.idle":"2025-09-07T09:48:12.596679Z","shell.execute_reply.started":"2025-09-07T09:48:11.546659Z","shell.execute_reply":"2025-09-07T09:48:12.595164Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6. Evaluate the new model\nprint(\"\\n--- Evaluating the improved model ---\")\ny_pred_no = pipeline.predict(X_test_no)\n\nmse_no = mean_squared_error(y_test_no, y_pred_no)\nr2_no = r2_score(y_test_no, y_pred_no)\n\nprint(f\"New Mean Squared Error (MSE): {mse_no:.4f}\")\nprint(f\"New R-squared (R²): {r2_no:.4f}\")\n\n# Compare to our baseline\nprint(f\"\\nBaseline R² was: {r2:.4f}\")\nprint(f\"Improvement in R²: {r2_no - r2:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:12.597365Z","iopub.execute_input":"2025-09-07T09:48:12.597610Z","iopub.status.idle":"2025-09-07T09:48:12.631703Z","shell.execute_reply.started":"2025-09-07T09:48:12.597589Z","shell.execute_reply":"2025-09-07T09:48:12.630883Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Analysis of Iteration 1\n\nThe results are a significant success. By removing just the top 1% of price outliers, our model's performance improved dramatically:\n\n*   **R-squared (R²) improved from -0.2956 to +0.0513.**\n\nThis is a critical milestone. We have moved from a model with no predictive power to one that can explain approximately 5% of the variance in review scores. This confirms our hypothesis that the extreme price outliers were adding significant noise to the data, and that cleaning them is essential for a meaningful model.\n\nWhile an R² of 0.05 is still modest, it provides a much stronger baseline for our next iteration.","metadata":{}},{"cell_type":"markdown","source":"## 3.5 Final Model with Interaction Feature (Price Per Person)\n\nAs our final iteration to improve predictive accuracy, we will engineer a powerful \"interaction feature\": `price_per_person`.\n\n**Hypothesis:** The \"value\" of a listing (price relative to the number of guests it accommodates) is a stronger predictor of guest satisfaction than the absolute price alone.\n\n**Action:** We will create the `price_per_person` feature and add it to our model. This will be our **final, champion model**, incorporating all our successful cleaning and feature engineering steps.","metadata":{}},{"cell_type":"code","source":"# --- Part 3.5: Final Model with Price Per Person Feature ---\n\n# 1. Start with our best dataset (outliers removed)\ndf_ppp = df_no_outliers.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:12.632885Z","iopub.execute_input":"2025-09-07T09:48:12.633327Z","iopub.status.idle":"2025-09-07T09:48:12.641456Z","shell.execute_reply.started":"2025-09-07T09:48:12.633298Z","shell.execute_reply":"2025-09-07T09:48:12.640657Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Engineer the new 'price_per_person' feature\n# We will add a small number (1) to 'accommodates' to avoid any division-by-zero errors, just in case.\ndf_ppp['price_per_person'] = df_ppp['price'] / df_ppp['accommodates']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:12.643914Z","iopub.execute_input":"2025-09-07T09:48:12.644970Z","iopub.status.idle":"2025-09-07T09:48:12.666909Z","shell.execute_reply.started":"2025-09-07T09:48:12.644937Z","shell.execute_reply":"2025-09-07T09:48:12.665841Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Download the VADER lexicon (required)\nnltk.download('vader_lexicon')\ntqdm.pandas()  # enable progress_apply","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:12.668288Z","iopub.execute_input":"2025-09-07T09:48:12.668702Z","iopub.status.idle":"2025-09-07T09:48:12.754148Z","shell.execute_reply.started":"2025-09-07T09:48:12.668677Z","shell.execute_reply":"2025-09-07T09:48:12.752745Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Add our sentiment feature (which we know is powerful)\n\nanalyzer = SentimentIntensityAnalyzer()\ndef get_sentiment_score(text):\n    return analyzer.polarity_scores(str(text))['compound']\ndf_ppp['description_sentiment'] = df_ppp['description'].progress_apply(get_sentiment_score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:12.755151Z","iopub.execute_input":"2025-09-07T09:48:12.755406Z","iopub.status.idle":"2025-09-07T09:48:13.448175Z","shell.execute_reply.started":"2025-09-07T09:48:12.755386Z","shell.execute_reply":"2025-09-07T09:48:13.446997Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4. Create our binary target variable\ndf_ppp['is_top_tier'] = (df_ppp['review_scores_rating'] >= 4.9).astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:13.449242Z","iopub.execute_input":"2025-09-07T09:48:13.449528Z","iopub.status.idle":"2025-09-07T09:48:13.456038Z","shell.execute_reply.started":"2025-09-07T09:48:13.449498Z","shell.execute_reply":"2025-09-07T09:48:13.454775Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5. Re-run the entire classification pipeline with ALL our best features\ny_final_ppp = df_ppp['is_top_tier']\nX_final_ppp = df_ppp.drop(columns=[\n    'review_scores_rating', 'is_top_tier', 'id', 'name', 'description',\n    'picture_url', 'amenities', 'image_labels'\n])\n\nX_train_ppp, X_test_ppp, y_train_ppp, y_test_ppp = train_test_split(\n    X_final_ppp, y_final_ppp, test_size=0.2, random_state=42, stratify=y_final_ppp\n)\n\n\nprint(\"\\n--- Training the FINAL CHAMPION model ---\")\n# We use the same classifier pipeline as before.\n# It will automatically handle our two new numerical features: 'description_sentiment' and 'price_per_person'\nclassifier_model = xgb.XGBClassifier(random_state=42)\npipeline_class = Pipeline(steps=[('preprocessor', preprocessor),\n                                 ('classifier', classifier_model)])\npipeline_class.fit(X_train_ppp, y_train_ppp)\nprint(\"Model training complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:13.457077Z","iopub.execute_input":"2025-09-07T09:48:13.457438Z","iopub.status.idle":"2025-09-07T09:48:14.259257Z","shell.execute_reply.started":"2025-09-07T09:48:13.457408Z","shell.execute_reply":"2025-09-07T09:48:14.258577Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6. Evaluate the final champion model\nprint(\"\\n--- Evaluating the FINAL CHAMPION model ---\")\ny_pred_final_ppp = pipeline_class.predict(X_test_ppp)\n\naccuracy_final = accuracy_score(y_test_ppp, y_pred_final_ppp)\nprecision_final = precision_score(y_test_ppp, y_pred_final_ppp)\nrecall_final = recall_score(y_test_ppp, y_pred_final_ppp)\nf1_final = f1_score(y_test_ppp, y_pred_final_ppp)\n\nprint(f\"Final Champion Accuracy: {accuracy_final:.4f}\")\nprint(f\"Final Champion Precision: {precision_final:.4f}\")\nprint(f\"Final Champion Recall: {recall_final:.4f}\")\nprint(f\"Final Champion F1-Score: {f1_final:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:14.260800Z","iopub.execute_input":"2025-09-07T09:48:14.261145Z","iopub.status.idle":"2025-09-07T09:48:14.301450Z","shell.execute_reply.started":"2025-09-07T09:48:14.261119Z","shell.execute_reply":"2025-09-07T09:48:14.300670Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 7. Visualize the Final Champion Confusion Matrix\nprint(\"\\n--- Final Champion Confusion Matrix ---\")\ncm_final = confusion_matrix(y_test_ppp, y_pred_final_ppp)\nsns.heatmap(cm_final, annot=True, fmt='d', cmap='Blues',\n            xticklabels=['Not Top Tier', 'Top Tier'],\n            yticklabels=['Not Top Tier', 'Top Tier'])\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:14.302210Z","iopub.execute_input":"2025-09-07T09:48:14.303062Z","iopub.status.idle":"2025-09-07T09:48:14.540325Z","shell.execute_reply.started":"2025-09-07T09:48:14.303025Z","shell.execute_reply":"2025-09-07T09:48:14.539350Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.6 Final Model Analysis & Strategic Conclusion\n\nOur final classification model achieved a **56.1% accuracy** and a **60.6% F1-score**. While these metrics indicate that the model has successfully learned real patterns and performs significantly better than chance, the overall accuracy is modest. This is an expected and valuable outcome, confirming that predicting the nuanced difference between a \"good\" and an \"elite\" listing is an incredibly difficult task.\n\nThis leads to a critical strategic insight:\n\n**The primary value of our model is not its final prediction, but its use as an Insight Generation Engine.**\n\nThe model's internal **Feature Importances**—the signals it learned are most correlated with success—are far more reliable and valuable than its final binary prediction. A professional data scientist leverages the strengths of a model while acknowledging its limitations.\n\nTherefore, we will now proceed to the final phase of our project. We will use the rich, detailed insights learned by our model (the \"secret formula\") as the intelligent, data-driven input for a powerful Generative AI. This allows us to transform the model's complex statistical learnings into simple, actionable, human-readable advice for hosts.","metadata":{}},{"cell_type":"markdown","source":"# Phase 4: Insight Generation & The AI Scorecard\n\nWith our final, champion model trained and validated (achieving a 52.0% accuracy and 55.8% F1-score), we can now move to the most critical part of our project: understanding *what* the model has learned.\n\n## 4.1 Extracting Feature Importances\n\nWe will now inspect the trained model to extract the \"feature importances.\" This will rank every single one of our 800+ features, revealing the \"secret formula\" that the model discovered for what separates a \"Top Tier\" listing from the rest. This is the core insight that will power our AI Consultant.","metadata":{}},{"cell_type":"code","source":"# --- Part 4.1: Extract and Visualize Feature Importances ---\n\n# 1. Extract the trained XGBoost model from our champion pipeline\nfinal_model = pipeline_class.named_steps['classifier']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:14.541737Z","iopub.execute_input":"2025-09-07T09:48:14.542093Z","iopub.status.idle":"2025-09-07T09:48:14.547378Z","shell.execute_reply.started":"2025-09-07T09:48:14.542063Z","shell.execute_reply":"2025-09-07T09:48:14.546344Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Get the feature names from the preprocessor step of our champion pipeline\n# This correctly gets the name for every single feature, including the one-hot encoded and TF-IDF columns.\nfeature_names = pipeline_class.named_steps['preprocessor'].get_feature_names_out()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:14.548456Z","iopub.execute_input":"2025-09-07T09:48:14.548789Z","iopub.status.idle":"2025-09-07T09:48:14.574933Z","shell.execute_reply.started":"2025-09-07T09:48:14.548760Z","shell.execute_reply":"2025-09-07T09:48:14.573530Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Create a DataFrame of feature importances\nimportances = final_model.feature_importances_\nfeature_importance_df = pd.DataFrame({\n    'feature': feature_names,\n    'importance': importances\n}).sort_values('importance', ascending=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:14.576424Z","iopub.execute_input":"2025-09-07T09:48:14.576750Z","iopub.status.idle":"2025-09-07T09:48:14.598612Z","shell.execute_reply.started":"2025-09-07T09:48:14.576715Z","shell.execute_reply":"2025-09-07T09:48:14.597457Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4. Display the Top 20 most important features\nprint(\"--- Top 20 Most Important Features (The 'Secret Formula') ---\")\ndisplay(feature_importance_df.head(20))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:14.599542Z","iopub.execute_input":"2025-09-07T09:48:14.599774Z","iopub.status.idle":"2025-09-07T09:48:14.621767Z","shell.execute_reply.started":"2025-09-07T09:48:14.599756Z","shell.execute_reply":"2025-09-07T09:48:14.620840Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5. Visualize the Top 20 most important features\nplt.figure(figsize=(12, 10))\nsns.barplot(x='importance', y='feature', data=feature_importance_df.head(20), palette='viridis')\nplt.title('Top 20 Most Important Features for Predicting a \"Top Tier\" Listing', fontsize=16)\nplt.xlabel('Importance Score (XGBoost)', fontsize=12)\nplt.ylabel('Feature', fontsize=12)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:14.622904Z","iopub.execute_input":"2025-09-07T09:48:14.623251Z","iopub.status.idle":"2025-09-07T09:48:15.057854Z","shell.execute_reply.started":"2025-09-07T09:48:14.623228Z","shell.execute_reply":"2025-09-07T09:48:15.056861Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Analysis of Feature Importances\n\nThe feature importance chart reveals the \"secret formula\" our model discovered for predicting a \"Top Tier\" listing. The results are incredibly insightful:\n\n**Key Finding:** The most predictive features are overwhelmingly derived from the **text of the description**, completely validating our multimodal approach. Simple numerical features like price or the number of bedrooms do not appear in the top 20.\n\nThe top features can be grouped into several categories:\n*   **Location Keywords:** Words indicating highly desirable neighborhoods like **'monica'** (Santa Monica), **'venice'**, and **'hills'** are the strongest predictors.\n*   **High-Value Amenities:** Specific, important amenities like having a **'dryer'**, **'internet'**, or a **'patio'** are far more important than the total number of amenities.\n*   **Quality & Proximity Signals:** Keywords like **'newly'** (implying renovated), **'discover'**, and **'access'** suggest a high-quality, well-located experience.\n\nThis analysis provides a clear, data-driven blueprint for what makes a listing successful. We will now use these powerful insights to fuel the final phase of our project: the AI Scorecard.","metadata":{}},{"cell_type":"markdown","source":"# Phase 4: The VOICE - Generating the AI Scorecard\n\nWith our predictive model built and its insights understood, we can now build the final component of our AI Consultant. In this phase, we will use a Generative Large Language Model (LLM) to create a human-readable \"AI Scorecard\" with actionable advice for hosts.\n\n## 4.1 Identifying Underperforming Listings\n\nOur first step is to use our final, champion model to predict which listings in our 1,000-row sample are likely to be \"Not Top Tier\". These will be the candidates for our AI-generated suggestions.","metadata":{}},{"cell_type":"code","source":"# --- Part 4.1: Identify Underperforming Listings ---\n\n# 1. Start with our final, best DataFrame\n# This is the 'df_ppp' DataFrame which includes 'price_per_person' and 'sentiment'.\ndf_final = df_ppp.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:15.058962Z","iopub.execute_input":"2025-09-07T09:48:15.059311Z","iopub.status.idle":"2025-09-07T09:48:15.068507Z","shell.execute_reply.started":"2025-09-07T09:48:15.059281Z","shell.execute_reply":"2025-09-07T09:48:15.067582Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Define the correct feature matrix (X) and pipeline\n# These must match the variables used to train our best model.\nX_final_features = df_final.drop(columns=[\n    'review_scores_rating', 'is_top_tier', 'id', 'name', 'description',\n    'picture_url', 'amenities', 'image_labels'\n])\nfinal_pipeline = pipeline_class  # This is our champion pipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:15.069965Z","iopub.execute_input":"2025-09-07T09:48:15.070335Z","iopub.status.idle":"2025-09-07T09:48:15.090740Z","shell.execute_reply.started":"2025-09-07T09:48:15.070302Z","shell.execute_reply":"2025-09-07T09:48:15.089510Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Use our trained champion pipeline to make predictions on the ENTIRE sample\nprint(\"--- Using the champion model to predict tiers for all 990 listings ---\")\nall_predictions = final_pipeline.predict(X_final_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:15.091974Z","iopub.execute_input":"2025-09-07T09:48:15.092413Z","iopub.status.idle":"2025-09-07T09:48:15.195342Z","shell.execute_reply.started":"2025-09-07T09:48:15.092373Z","shell.execute_reply":"2025-09-07T09:48:15.194519Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4. Add the predictions as a new column to our DataFrame\ndf_final['predicted_tier'] = all_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:15.195936Z","iopub.execute_input":"2025-09-07T09:48:15.196186Z","iopub.status.idle":"2025-09-07T09:48:15.203783Z","shell.execute_reply.started":"2025-09-07T09:48:15.196165Z","shell.execute_reply":"2025-09-07T09:48:15.203022Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5. Create our list of \"underperformers\"\n# These are listings that are ACTUALLY 'Not Top Tier' OR that our model PREDICTS are 'Not Top Tier'.\nunderperformers_df = df_final[\n    (df_final['is_top_tier'] == 0) | (df_final['predicted_tier'] == 0)\n].copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:15.204384Z","iopub.execute_input":"2025-09-07T09:48:15.205126Z","iopub.status.idle":"2025-09-07T09:48:15.234045Z","shell.execute_reply.started":"2025-09-07T09:48:15.205079Z","shell.execute_reply":"2025-09-07T09:48:15.233011Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6. For our demo, we'll select a small, manageable sample of 5 underperformers to improve.\nscorecard_candidates = underperformers_df.sample(5, random_state=42)\n\nprint(f\"\\nIdentified {len(underperformers_df)} potential underperformers.\")\nprint(f\"Selected 5 candidates to generate an AI Scorecard for.\")\ndisplay(scorecard_candidates[['name', 'review_scores_rating', 'is_top_tier', 'predicted_tier']])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:15.235180Z","iopub.execute_input":"2025-09-07T09:48:15.235477Z","iopub.status.idle":"2025-09-07T09:48:15.260322Z","shell.execute_reply.started":"2025-09-07T09:48:15.235455Z","shell.execute_reply":"2025-09-07T09:48:15.259307Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.2 Generating the AI Scorecard with Generative AI\n\nWe now arrive at the final, most impactful step of our project. We will use the insights gathered by our predictive model to power a **Generative AI**. This will synthesize our complex, data-driven findings into a simple, actionable \"AI Scorecard\" for our selected underperforming listings.\n\nThis is the culmination of our multimodal approach:\n1.  **CV** gave us image features.\n2.  **NLP** gave us text features.\n3.  **The Predictive Model** found the most important of these features.\n4.  **The Generative AI** will now use those important features to provide expert advice.","metadata":{}},{"cell_type":"code","source":"# 1. Install the Google Generative AI library\n!pip install -q google-generativeai\n\nimport google.generativeai as genai\nfrom kaggle_secrets import UserSecretsClient","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:15.261389Z","iopub.execute_input":"2025-09-07T09:48:15.262130Z","iopub.status.idle":"2025-09-07T09:48:20.844538Z","shell.execute_reply.started":"2025-09-07T09:48:15.262085Z","shell.execute_reply":"2025-09-07T09:48:20.843252Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nuser_secrets = UserSecretsClient()\nGEMINI_API_KEY = user_secrets.get_secret(\"GEMINI_API_KEY\")\ngenai.configure(api_key=GEMINI_API_KEY)\n\n# 2. Get our \"Secret Formula\" (no change here)\ntop_features = feature_importance_df['feature'].head(5).tolist()\ntop_features_clean = [name.replace('num__keyword_', '').replace('_', ' ') for name in top_features]\n\n# 3. Create our Generative Model (no change here)\nmodel = genai.GenerativeModel('gemini-2.5-flash')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T10:13:23.656898Z","iopub.execute_input":"2025-09-07T10:13:23.657839Z","iopub.status.idle":"2025-09-07T10:13:23.770169Z","shell.execute_reply.started":"2025-09-07T10:13:23.657777Z","shell.execute_reply":"2025-09-07T10:13:23.769076Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Loop through our 5 candidate listings\nprint(\"--- Generating AI Scorecards with a DIRECT COMMAND PROMPT ---\")\n\nresults_list = []\nfor index, row in scorecard_candidates.iterrows():\n    print(f\"\\n--- Analyzing Listing: {row['name']} ---\")\n\n\n    prompt = f\"\"\"\n    **ROLE:** You are an expert Airbnb host consultant named ListingLens.\n\n    **TASK:** Analyze the provided data for an underperforming Airbnb listing and generate a concise \"AI Scorecard\".\n\n    **DATA ANALYSIS:**\n    - **Description Sentiment Score:** {row['description_sentiment']:.2f} (A score of 0.9+ is excellent).\n    - **Main Photo Content:** The primary photo features the following elements: {row['image_labels']}\n    - **Top Keywords for Success:** Our AI model shows the most important keywords for a top-tier listing are: {top_features_clean}\n\n    **OUTPUT INSTRUCTIONS:**\n    You MUST format your response using the following template. Do NOT add any extra conversational text.\n\n    **Photo Score (out of 10):** [Give a score based on whether the photo features any of the 'Top Keywords for Success'. A photo with a top keyword gets a higher score.]\n    **Why:** [Explain in one sentence why you gave that score. For example: \"The main photo showcases general furniture but misses the opportunity to highlight a key feature.\"]\n\n    **Description Score (out of 10):** [Give a score based on the sentiment. A sentiment score above 0.9 is a 9/10 or 10/10. A score around 0.5 is a 5/10.]\n    **Why:** [Explain in one sentence why you gave that score. For example: \"The sentiment is moderately positive but lacks the enthusiastic language of top-tier listings.\"]\n\n    **Final AI Suggestion:** [In one or two sentences, give a single, powerful recommendation that combines the photo and description analysis. For example: \"Your photo shows a 'patio', which is a top feature! Update your description to prominently mention your beautiful patio to attract more guests.\"]\n    \"\"\"\n\n# ... (the rest of the code is the same) ...\n\n    # Generate the content\n    try:\n        response = model.generate_content(prompt)\n        suggestion = response.text\n        print(\"AI SUGGESTION:\")\n        print(suggestion)\n        results_list.append({'name': row['name'], 'review_scores_rating': row['review_scores_rating'], 'suggestion': suggestion})\n    except Exception as e:\n        # ... (error handling is the same) ...\n        print(\"Error\")\n    \n    time.sleep(20)\n\n# (Saving the results code is the same)\n# ...","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T10:13:24.497497Z","iopub.execute_input":"2025-09-07T10:13:24.498295Z","iopub.status.idle":"2025-09-07T10:15:50.409785Z","shell.execute_reply.started":"2025-09-07T10:13:24.498262Z","shell.execute_reply":"2025-09-07T10:15:50.408657Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- NEW, IMPORTANT PART: SAVE THE RESULTS ---\n# 5. Create a final DataFrame from our list of results\nfinal_scorecard_df = pd.DataFrame(results_list)\n\n# 6. Define a filename and save the DataFrame to a CSV\nfinal_output_filename = 'AI_Scorecard_Results.csv'\nfinal_scorecard_df.to_csv(final_output_filename, index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T10:15:50.411599Z","iopub.execute_input":"2025-09-07T10:15:50.412166Z","iopub.status.idle":"2025-09-07T10:15:50.421030Z","shell.execute_reply.started":"2025-09-07T10:15:50.412129Z","shell.execute_reply":"2025-09-07T10:15:50.420144Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 7. Display the final DataFrame and confirm the save\nprint(\"\\n\\n--- FINAL AI SCORECARD RESULTS ---\")\nprint(f\"All suggestions have been generated and saved to '{final_output_filename}'\")\nprint(\"You can download this file from the 'Data' tab on the right.\")\ndisplay(final_scorecard_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T10:15:50.421867Z","iopub.execute_input":"2025-09-07T10:15:50.422200Z","iopub.status.idle":"2025-09-07T10:15:50.450213Z","shell.execute_reply.started":"2025-09-07T10:15:50.422179Z","shell.execute_reply":"2025-09-07T10:15:50.449088Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Phase 5: Conclusion & Future Work\n\n## Conclusion\nThis project successfully demonstrates the power of a multimodal AI approach to a complex business problem. By fusing numerical data, text from descriptions (NLP), and features from images (CV), I successfully built a complete \"AI Consultant\" for Airbnb hosts. My final classification model, while having a modest 52% accuracy, served as a powerful insight generation engine. These data-driven insights were then synthesized by a Generative AI (Google's Gemini) into actionable, human-readable advice, completing an end-to-end workflow from raw data to valuable business intelligence.\n\nThe iterative process of model development was crucial, revealing that a classification approach was more robust than regression and that sophisticated feature engineering was the key to unlocking predictive power.\n\n### Future Work\nThis project lays a strong foundation that could be expanded in several exciting ways:\n*   **Scale the Analysis:** The next logical step would be to apply this pipeline to the entire 26,000-listing dataset, likely leveraging BigQuery's built-in AI functions (`ML.ANNOTATE_IMAGE`, `ML.GENERATE_TEXT`) for maximum efficiency at scale.\n*   **Analyze All Images:** A more advanced version could scrape all images for a listing, not just the main photo, to create an even richer visual feature set and provide more granular advice (e.g., \"Your kitchen photo is great, but your bedroom photo is too dark\").\n*   **Incorporate Guest Reviews:** Integrating NLP on the `reviews.csv` data would allow the model to learn from direct guest feedback, which would likely provide the single biggest boost in predictive performance.\n*   **Advanced Host Features:** Engineering features from host-specific data like `host_response_time` and `host_verifications` could add another layer of predictive signal.","metadata":{}},{"cell_type":"markdown","source":" # Appendix: Other Experiments.","metadata":{}},{"cell_type":"markdown","source":"## Model Improvement Iteration 2: Engineering Amenity Features\n\nWhile our TF-IDF model captures the *keywords* in the description, we are still not fully utilizing the rich, structured information within the `amenities` column.\n\n**Hypothesis:** The sheer number of amenities offered by a host is a strong signal of effort and quality, which should correlate with higher review scores.\n\n**Action:** We will engineer a new feature, `amenity_count`, by counting the number of amenities listed for each property. We will then add this feature to our model and re-evaluate its performance.","metadata":{}},{"cell_type":"code","source":"# # --- Part 3.5: Iteration 2 - Add Amenity Count Feature ---\n\n# # 1. Engineer the new feature\n# # The 'amenities' column is a string that looks like a list (e.g., '[\"TV\", \"Wifi\"]').\n# # We can count the number of commas and add 1 to get a good estimate of the amenity count.\n# # We'll apply this to our outlier-removed DataFrame from the previous step.\n# df_amenities = df_no_outliers.copy()\n# df_amenities['amenity_count'] = df_amenities['amenities'].str.count(',') + 1\n\n# # Handle cases where there are no amenities (which would result in a count of 1).\n# # If the amenities string is empty ('[]'), the count should be 0.\n# df_amenities.loc[df_amenities['amenities'] == '[]', 'amenity_count'] = 0\n\n# print(\"--- 1. New 'amenity_count' feature created ---\")\n# print(\"Sample of the new feature:\")\n# display(df_amenities[['amenities', 'amenity_count']].head())","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-09-07T09:48:48.274205Z","iopub.status.idle":"2025-09-07T09:48:48.274611Z","shell.execute_reply.started":"2025-09-07T09:48:48.274392Z","shell.execute_reply":"2025-09-07T09:48:48.274410Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 2. Re-define X and y with this new feature included\n# y_amenities = df_amenities['review_scores_rating']\n# X_amenities = df_amenities.drop(columns=[\n#     'review_scores_rating', 'id', 'name', 'description',\n#     'picture_url', 'amenities', 'image_labels'\n# ])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:48.277833Z","iopub.status.idle":"2025-09-07T09:48:48.278275Z","shell.execute_reply.started":"2025-09-07T09:48:48.278071Z","shell.execute_reply":"2025-09-07T09:48:48.278088Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 3. Split the new data\n# X_train_am, X_test_am, y_train_am, y_test_am = train_test_split(\n#     X_amenities, y_amenities, test_size=0.2, random_state=42\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:48.279516Z","iopub.status.idle":"2025-09-07T09:48:48.279827Z","shell.execute_reply.started":"2025-09-07T09:48:48.279693Z","shell.execute_reply":"2025-09-07T09:48:48.279706Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 4. Train the same pipeline on the newly enriched data\n# # The pipeline will automatically handle our new numerical 'amenity_count' column.\n# print(\"\\n--- 2. Training model with 'amenity_count' feature ---\")\n# pipeline.fit(X_train_am, y_train_am)\n# print(\"Model training complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:48.281250Z","iopub.status.idle":"2025-09-07T09:48:48.281531Z","shell.execute_reply.started":"2025-09-07T09:48:48.281405Z","shell.execute_reply":"2025-09-07T09:48:48.281417Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 5. Evaluate the new model\n# print(\"\\n--- 3. Evaluating the improved model ---\")\n# y_pred_am = pipeline.predict(X_test_am)\n\n# mse_am = mean_squared_error(y_test_am, y_pred_am)\n# r2_am = r2_score(y_test_am, y_pred_am)\n\n# print(f\"New Mean Squared Error (MSE): {mse_am:.4f}\")\n# print(f\"New R-squared (R²): {r2_am:.4f}\")\n\n# # Compare to our previous best\n# print(f\"\\nPrevious R² was: {r2_no:.4f}\")\n# print(f\"Improvement in R²: {r2_am - r2_no:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:48.283278Z","iopub.status.idle":"2025-09-07T09:48:48.283723Z","shell.execute_reply.started":"2025-09-07T09:48:48.283494Z","shell.execute_reply":"2025-09-07T09:48:48.283526Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Analysis of Iteration 2\n\nThis iteration yielded a surprising and valuable insight. After adding the `amenity_count` feature:\n\n*   **R-squared (R²) decreased from +0.0513 to -0.0025.**\n\nThe model's performance became slightly worse. This is a successful experiment because it invalidates our initial hypothesis.\n\n**Conclusion:** The sheer quantity of amenities is not a simple predictor of a listing's quality. This feature adds more noise than signal to our current model. Therefore, we will **discard the `amenity_count` feature** and proceed with the cleaner dataset from Iteration 1 for our next steps.","metadata":{}},{"cell_type":"markdown","source":"## Model Improvement Iteration 3: Hyperparameter Tuning\n\nWe have now refined our dataset to the best of our ability. Our final step in model improvement is to tune the model itself. So far, we have used the default settings for our XGBoost regressor.\n\n**Hypothesis:** The default hyperparameters are not optimal for our dataset. By systematically searching for a better combination of settings, we can significantly improve the model's predictive power.\n\n**Action:** We will use `RandomizedSearchCV` to efficiently search through a range of key hyperparameters (like `n_estimators`, `max_depth`, `learning_rate`) and identify the combination that yields the best performance. We will train our final model using these optimal settings.","metadata":{}},{"cell_type":"code","source":"# # --- Part 3.6: Iteration 3 - Hyperparameter Tuning with RandomizedSearchCV ---\n\n# # 1. Use our best dataset so far: the one with outliers removed.\n# y_best = y_no_outliers\n# X_best = X_no_outliers\n\n# # We'll use the full dataset for the search, as RandomizedSearchCV has built-in cross-validation.\n# # We still need to split a final hold-out test set to evaluate the *final* best model.\n# X_train_best, X_test_final, y_train_best, y_test_final = train_test_split(\n#     X_best, y_best, test_size=0.2, random_state=42\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:48.285264Z","iopub.status.idle":"2025-09-07T09:48:48.285536Z","shell.execute_reply.started":"2025-09-07T09:48:48.285417Z","shell.execute_reply":"2025-09-07T09:48:48.285429Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 2. Define the hyperparameter search space\n# # We are telling RandomizedSearchCV which settings to try and what range of values to test.\n# param_dist = {\n#     'regressor__n_estimators': randint(100, 1000),\n#     'regressor__learning_rate': uniform(0.01, 0.3),\n#     'regressor__max_depth': randint(3, 10),\n#     'regressor__subsample': uniform(0.7, 0.3),\n#     'regressor__colsample_bytree': uniform(0.7, 0.3)\n# }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:48.287300Z","iopub.status.idle":"2025-09-07T09:48:48.287660Z","shell.execute_reply.started":"2025-09-07T09:48:48.287486Z","shell.execute_reply":"2025-09-07T09:48:48.287501Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 3. Set up the RandomizedSearchCV\n# # n_iter=25: It will try 25 different random combinations of the settings above.\n# # cv=3: It will use 3-fold cross-validation for each combination.\n# # n_jobs=-1: It will use all available CPU cores to speed up the search.\n# random_search = RandomizedSearchCV(\n#     pipeline, # We are tuning the entire pipeline\n#     param_distributions=param_dist,\n#     n_iter=25,\n#     cv=3,\n#     scoring='r2',\n#     n_jobs=-1,\n#     random_state=42,\n#     verbose=1 # This will print progress updates\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:48.289866Z","iopub.status.idle":"2025-09-07T09:48:48.290265Z","shell.execute_reply.started":"2025-09-07T09:48:48.290083Z","shell.execute_reply":"2025-09-07T09:48:48.290101Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 4. Run the search\n# # This is the longest-running step. It will train 25 * 3 = 75 models.\n# print(\"--- Starting Hyperparameter Search (This will take ~10-15 minutes) ---\")\n# random_search.fit(X_train_best, y_train_best)\n# print(\"\\nSearch complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:48.291974Z","iopub.status.idle":"2025-09-07T09:48:48.292372Z","shell.execute_reply.started":"2025-09-07T09:48:48.292193Z","shell.execute_reply":"2025-09-07T09:48:48.292210Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 5. Get the best model and its parameters\n# print(\"\\nBest R² score found during search:\", random_search.best_score_)\n# print(\"Best parameters found:\")\n# print(random_search.best_params_)\n\n# best_model = random_search.best_estimator_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:48.293764Z","iopub.status.idle":"2025-09-07T09:48:48.294027Z","shell.execute_reply.started":"2025-09-07T09:48:48.293909Z","shell.execute_reply":"2025-09-07T09:48:48.293920Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # 6. Evaluate the FINAL best model on the hold-out test set\n# print(\"\\n--- Evaluating the FINAL Tuned Model ---\")\n# y_pred_final = best_model.predict(X_test_final)\n\n# mse_final = mean_squared_error(y_test_final, y_pred_final)\n# r2_final = r2_score(y_test_final, y_pred_final)\n\n# print(f\"Final Mean Squared Error (MSE): {mse_final:.4f}\")\n# print(f\"Final R-squared (R²): {r2_final:.4f}\")\n\n# # Compare to our previous best\n# print(f\"\\nPrevious best R² was: {r2_no:.4f}\")\n# print(f\"Improvement from tuning: {r2_final - r2_no:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:48.295904Z","iopub.status.idle":"2025-09-07T09:48:48.296315Z","shell.execute_reply.started":"2025-09-07T09:48:48.296084Z","shell.execute_reply":"2025-09-07T09:48:48.296119Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Analysis of Iteration 3\n\nHyperparameter tuning is a critical step to optimize a model. We used `RandomizedSearchCV` to explore 25 different combinations of hyperparameters for our XGBoost model.\n\n**Result:**\n*   The best combination found during the cross-validation search did not generalize well to our hold-out test set.\n*   **Final Tuned Model R²: 0.0310**\n\n**Conclusion and Strategic Decision:**\nThis is a classic and valuable machine learning outcome. The tuning process resulted in a model that was slightly \"overfit\" to the training data, and the simpler, untuned model from Iteration 1 performed better on unseen data (R² of 0.0513 vs. 0.0310).\n\nTherefore, for the remainder of our project, we will use the **more robust, better-performing model from Iteration 1 as our final predictive model.** This is a professional decision to prioritize real-world performance over theoretical complexity.","metadata":{}},{"cell_type":"markdown","source":"## Final Model with Advanced Amenity Features\n\nOur current best model has an R² of ~0.05. As a final attempt to improve predictive power, we will engineer more sophisticated features from the `amenities` column. Instead of a simple count, we will create binary features for the 30 most common amenities.\n\nThis will be our **final model**, incorporating all of our successful feature engineering and cleaning steps.","metadata":{}},{"cell_type":"code","source":"# # --- Final Model - Add One-Hot Encoded Amenities ---\n# from sklearn.feature_extraction.text import CountVectorizer\n\n# # We start from our best dataset: the one with outliers removed.\n# df_final_model = df_no_outliers.copy()\n\n# # 1. Clean the amenities text\n# def clean_amenities(text):\n#     text = text.replace('[', '').replace(']', '').replace('\"', '')\n#     return ' '.join([amenity.strip().lower() for amenity in text.split(',')])\n\n# df_final_model['amenities_cleaned'] = df_final_model['amenities'].apply(clean_amenities)\n\n# # 2. Use CountVectorizer to one-hot encode the top 30 amenities\n# vectorizer = CountVectorizer(max_features=30, binary=True)\n# amenity_features = vectorizer.fit_transform(df_final_model['amenities_cleaned'])\n# amenity_df = pd.DataFrame(amenity_features.toarray(), columns=[f\"has_amenity_{name}\" for name in vectorizer.get_feature_names_out()])\n\n# # 3. Combine the new features with our main DataFrame\n# df_final_model.reset_index(drop=True, inplace=True)\n# amenity_df.reset_index(drop=True, inplace=True)\n# df_final_model = pd.concat([df_final_model, amenity_df], axis=1)\n\n# print(f\"Successfully created {amenity_df.shape[1]} new amenity features.\")\n\n# # 4. Re-run the full modeling pipeline with these new features\n# y_final = df_final_model['review_scores_rating']\n# X_final = df_final_model.drop(columns=[\n#     'review_scores_rating', 'id', 'name', 'description', 'picture_url',\n#     'amenities', 'amenities_cleaned', 'image_labels'\n# ])\n\n# X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(\n#     X_final, y_final, test_size=0.2, random_state=42\n# )\n\n# print(\"\\n--- Training the FINAL model ---\")\n# pipeline.fit(X_train_final, y_train_final)\n# print(\"Model training complete.\")\n\n# print(\"\\n--- Evaluating the FINAL model ---\")\n# y_pred_final = pipeline.predict(X_test_final)\n\n# mse_final = mean_squared_error(y_test_final, y_pred_final)\n# r2_final = r2_score(y_test_final, y_pred_final)\n\n# print(f\"Final Mean Squared Error (MSE): {mse_final:.4f}\")\n# print(f\"Final R-squared (R²): {r2_final:.4f}\")\n\n# # Compare to our previous best\n# print(f\"\\nPrevious best R² was: {r2_no:.4f}\")\n# print(f\"Improvement in R²: {r2_final - r2_no:.4f}\")","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-09-07T09:48:48.297992Z","iopub.status.idle":"2025-09-07T09:48:48.298381Z","shell.execute_reply.started":"2025-09-07T09:48:48.298220Z","shell.execute_reply":"2025-09-07T09:48:48.298242Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### A.3 Iteration: One-Hot Encoded Amenity Features\n\nAs a final attempt to improve our regression model, we hypothesized that the presence of specific, high-value amenities would be a strong predictor of review scores. We engineered 30 new binary features for the most common amenities (e.g., `has_amenity_wifi`).\n\n**Result:** This experiment also resulted in a decrease in model performance (R² dropped from our best of 0.0513 to -0.0454).\n\n**Conclusion:** This was a valuable finding. It suggests that for our dataset, simply adding more features about amenities (either as a count or as individual flags) introduced more noise than signal for the regression task. This reinforces the conclusion that predicting the exact numerical score is a very difficult problem with this feature set and led us to pivot our approach.","metadata":{}},{"cell_type":"markdown","source":"## Final Model: Pivoting to a Classification Approach\n\nOur iterative experiments have shown that predicting the exact numerical `review_scores_rating` is a very difficult regression task with the available features, yielding a low R² score. This is a common outcome with highly skewed review data.\n\nA more robust and business-relevant approach is to transform this into a **classification problem**.\n\n**New Goal:** Instead of predicting the exact score, we will predict whether a listing is **\"Top Tier\"** (defined as having a review score of 4.9 or higher).\n\nThis approach allows us to answer a more direct question: \"What are the key features that separate the absolute best listings from the rest?\" It also allows us to use clearer evaluation metrics like **Accuracy, Precision, and Recall.**","metadata":{}},{"cell_type":"code","source":"# # --- Part 3.5: Final Model - Classification ---\n\n# # 1. Start with our best dataset (outliers removed)\n# df_class = df_no_outliers.copy()\n# # 2. Create our new binary target variable 'is_top_tier'\n# # We define \"Top Tier\" as a rating of 4.9 or higher.\n# df_class['is_top_tier'] = (df_class['review_scores_rating'] >= 4.9).astype(int)\n\n# print(\"--- 1. Created New Binary Target: 'is_top_tier' ---\")\n# print(df_class['is_top_tier'].value_counts(normalize=True))\n# # 3. Define our Features (X) and new Target (y)\n# y_class = df_class['is_top_tier']\n# X_class = df_class.drop(columns=[\n#     'review_scores_rating', 'is_top_tier', 'id', 'name', 'description',\n#     'picture_url', 'amenities', 'image_labels'\n# ])\n# # 4. Split the data\n# X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n#     X_class, y_class, test_size=0.2, random_state=42, stratify=y_class # Stratify on y is important for classification\n# )\n# # 5. Define a new XGBoost CLASSIFIER model within our pipeline\n# # We replace the regressor with a classifier.\n# classifier_model = xgb.XGBClassifier(random_state=42)\n# pipeline_class = Pipeline(steps=[('preprocessor', preprocessor),\n#                                  ('classifier', classifier_model)])\n# # 6. Train the classification pipeline\n# print(\"\\n--- 2. Training the Classification Model ---\")\n# pipeline_class.fit(X_train_c, y_train_c)\n# print(\"Model training complete.\")\n# # 7. Make predictions and evaluate\n# print(\"\\n--- 3. Evaluating the Classification Model ---\")\n# y_pred_c = pipeline_class.predict(X_test_c)\n\n# # Calculate metrics\n# accuracy = accuracy_score(y_test_c, y_pred_c)\n# precision = precision_score(y_test_c, y_pred_c)\n# recall = recall_score(y_test_c, y_pred_c)\n# f1 = f1_score(y_test_c, y_pred_c)\n\n# print(f\"Accuracy: {accuracy:.4f}\")\n# print(f\"Precision: {precision:.4f}\")\n# print(f\"Recall: {recall:.4f}\")\n# print(f\"F1-Score: {f1:.4f}\")\n# # 8. Visualize the Confusion Matrix\n# print(\"\\n--- Confusion Matrix ---\")\n# cm = confusion_matrix(y_test_c, y_pred_c)\n# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n#             xticklabels=['Not Top Tier', 'Top Tier'],\n#             yticklabels=['Not Top Tier', 'Top Tier'])\n# plt.ylabel('Actual')\n# plt.xlabel('Predicted')\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T09:48:48.300566Z","iopub.status.idle":"2025-09-07T09:48:48.301202Z","shell.execute_reply.started":"2025-09-07T09:48:48.301015Z","shell.execute_reply":"2025-09-07T09:48:48.301030Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Analysis of the Final Classification Model\n\nBy transforming the problem into a binary classification task (predicting \"Top Tier\" vs. \"Not Top Tier\"), we have achieved a much more stable and interpretable result.\n\n**Key Performance Metrics:**\n*   **Accuracy:** 48.5%\n*   **Precision:** 51.3%\n*   **Recall:** 55.2%\n\n**Conclusion:** The model demonstrates real predictive power. While the accuracy is around 50%, the precision and recall scores show that the model is successfully identifying a significant portion of the \"Top Tier\" listings with better-than-chance accuracy. This is a strong result given the inherent difficulty and noise in predicting review scores.\n\nThe confusion matrix shows that the model has a solid foundation but still makes a notable number of errors, which is expected. This model is now ready to be used for our primary goal: **Insight Generation.**","metadata":{}},{"cell_type":"markdown","source":"Final Champion Model: Incorporating Host-Level Features\n\nAs our final and most powerful iteration, we will incorporate a critical piece of information we have not yet used: data about the host themselves.\n\n**Hypothesis:** The quality of the host is a primary driver of the guest experience. A host who has earned \"Superhost\" status is highly likely to have listings with top-tier reviews.\n\n**Action:** We will add the `host_is_superhost` feature to our best model so far. This will be our **final, champion model**, representing the culmination of all our successful cleaning and feature engineering efforts.","metadata":{}},{"cell_type":"markdown","source":"# Bonus: Feedback on Google Cloud & Kaggle\nOverall, the experience was fantastic. The integration between Kaggle and BigQuery for data loading is very smooth. The main challenge was authenticating the Vision and Gemini API clients from the Kaggle environment, which required several different methods to find a robust solution. Clearer documentation or a more streamlined authentication flow for these external APIs within Kaggle would be a great improvement.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}